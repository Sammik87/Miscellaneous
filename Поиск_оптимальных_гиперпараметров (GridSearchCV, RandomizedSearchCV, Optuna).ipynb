{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342426f9-ce7b-46c4-aec2-6152f7f62036",
   "metadata": {},
   "source": [
    "### **Что важно учитывать при использовании `GridSearchCV`?**\n",
    "\n",
    "1. **Выбор гиперпараметров:**\n",
    "   - Определите, какие гиперпараметры вы хотите оптимизировать. Например, для `RandomForestClassifier` это могут быть `n_estimators`, `max_depth`, `min_samples_split`.\n",
    "   - Не перегружайте сетку слишком большим количеством гиперпараметров, иначе поиск станет очень долгим.\n",
    "\n",
    "2. **Размер сетки параметров:**\n",
    "   - Убедитесь, что сетка покрывает разумный диапазон значений гиперпараметров.\n",
    "   - Для некоторых параметров (например, `learning_rate`) лучше использовать логарифмическую шкалу.\n",
    "\n",
    "3. **Кросс-валидация (`cv`):**\n",
    "   - Определяет, на сколько частей делится выборка (например, `cv=5` означает 5 фолдов).\n",
    "   - Используйте стратифицированную кросс-валидацию (`StratifiedKFold`) для несбалансированных данных.\n",
    "\n",
    "4. **Метрика:**\n",
    "   - Укажите метрику для оптимизации (например, `accuracy`, `roc_auc`, `neg_mean_squared_error`).\n",
    "   - Метрика должна соответствовать вашей задаче: классификация, регрессия и т.д.\n",
    "\n",
    "5. **Проблема переобучения:**\n",
    "   - Используйте отдельный тестовый набор данных для оценки модели после поиска гиперпараметров.\n",
    "   - Никогда не оптимизируйте гиперпараметры на тестовом наборе.\n",
    "\n",
    "6. **Параллелизация:**\n",
    "   - Для ускорения используйте параметр `n_jobs=-1`, чтобы задействовать все ядра процессора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde58fd-42f9-495b-8255-a18907a07c9e",
   "metadata": {},
   "source": [
    "### **Пример использования `GridSearchCV`**\n",
    "\n",
    "#### Пример задачи: Оптимизация гиперпараметров для `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d9a7f-d936-42ec-b521-b7be4dd5ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Генерация данных\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Модель\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Гиперпараметры для поиска\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Метрика для оптимизации\n",
    "    cv=5,  # 5-кратная кросс-валидация\n",
    "    n_jobs=-1,  # Использовать все процессоры\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Запуск поиска\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "\n",
    "# Оценка на тестовом наборе\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Точность на тестовом наборе:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2bce5-fc79-4cda-9a4f-9742f1b9d39e",
   "metadata": {},
   "source": [
    "### **Результат выполнения `GridSearchCV`**\n",
    "1. **`best_params_`:** Показывает комбинацию гиперпараметров, давшую наилучший результат.\n",
    "2. **`best_score_`:** Среднее качество модели (по метрике `scoring`) на кросс-валидации с лучшими гиперпараметрами.\n",
    "3. **`best_estimator_`:** Модель, обученная с лучшими гиперпараметрами.\n",
    "4. **`cv_results_`:** Полная информация о всех комбинациях гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea7bad-b995-481f-8e1b-6abef977a689",
   "metadata": {},
   "source": [
    "### **Альтернативы `GridSearchCV`**\n",
    "\n",
    "1. **`RandomizedSearchCV`:**\n",
    "   - Вместо полного перебора случайно выбирает комбинации гиперпараметров.\n",
    "   - Экономит время, особенно при большом количестве параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0c4d5-640e-4f51-83c1-be17305505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Случайный поиск\n",
    "param_distributions = {\n",
    "   'n_estimators': randint(50, 200),\n",
    "   'max_depth': [None, 10, 20, 30],\n",
    "   'min_samples_split': [2, 5, 10],\n",
    "   'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "   estimator=model,\n",
    "   param_distributions=param_distributions,\n",
    "   n_iter=20,  # Количество случайных комбинаций\n",
    "   scoring='accuracy',\n",
    "   cv=5,\n",
    "   n_jobs=-1,\n",
    "   random_state=42,\n",
    "   verbose=2\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры (RandomizedSearchCV):\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61aef9-eb3d-43b5-9b0c-0d2e0f3f08b9",
   "metadata": {},
   "source": [
    "2. **Bayesian Optimization (например, `Optuna`):**\n",
    "   - Умный перебор параметров с использованием вероятностных моделей.\n",
    "   - Быстрее, чем `GridSearchCV`, при этом результаты часто лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ecb11-9053-4ebe-922d-402590957f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "   n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "   max_depth = trial.suggest_int('max_depth', 10, 30, log=True)\n",
    "   min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "   min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "\n",
    "   model = RandomForestClassifier(\n",
    "       n_estimators=n_estimators,\n",
    "       max_depth=max_depth,\n",
    "       min_samples_split=min_samples_split,\n",
    "       min_samples_leaf=min_samples_leaf,\n",
    "       random_state=42\n",
    "   )\n",
    "   model.fit(X_train, y_train)\n",
    "   y_pred = model.predict(X_test)\n",
    "   return accuracy_score(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Лучшие параметры (Optuna):\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899620f-8684-4cd9-bfd2-628b57077f6d",
   "metadata": {},
   "source": [
    "### **Выводы**\n",
    "1. **GridSearchCV** хорошо работает для небольших задач, но может быть медленным при большом количестве гиперпараметров.\n",
    "2. **`RandomizedSearchCV`** быстрее, но менее детален.\n",
    "3. **Продвинутые методы (например, `Optuna`)** позволяют быстрее находить оптимальные параметры.\n",
    "4. **Важно всегда иметь тестовый набор**, который не используется в процессе выбора гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec951a2-5b8c-4532-852b-3db6de2925bb",
   "metadata": {},
   "source": [
    "# Работа с интервалами гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93dde7-7cd0-423e-9db3-730857593d14",
   "metadata": {},
   "source": [
    "Если гиперпараметры, найденные с помощью GridSearchCV, оказываются на границах заданных интервалов необходимо увеличить/изменить диапазон. Проверить влияние этих гиперпараметров на качество модели. Возможно, они не сильно влияют, и можно оставить их фиксированными.\n",
    "\n",
    "В процессе использования `GridSearchCV`, если вы видите, что какой-то из гиперпараметров достигает границы интервала, это сигнал для уточнения его диапазона. При этом диапазоны остальных гиперпараметров, у которых значения находятся внутри интервала, можно оставить без изменений. Вот как это делается:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09ced2-a7e9-40cb-b923-b13c00ec7ce9",
   "metadata": {},
   "source": [
    "### **1. Уточняем диапазон только для \"крайних\" гиперпараметров**\n",
    "Если один из гиперпараметров (например, `max_depth`) достигает верхней границы интервала, увеличиваем только его диапазон, оставляя другие неизменными.\n",
    "\n",
    "#### Пример:\n",
    "\n",
    "Допустим, вы провели поиск с таким диапазоном:\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, 30],  # \"30\" — крайнее значение\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "Результаты показали, что `max_depth=30` (крайнее значение), но другие гиперпараметры (`min_samples_split=5`, `min_samples_leaf=2`) находятся внутри интервалов. Вы можете расширить диапазон **только для `max_depth`**, например:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Оставляем неизменным\n",
    "    'max_depth': [20, 30, 40, 50],  # Увеличили диапазон\n",
    "    'min_samples_split': [2, 5, 10],  # Оставляем неизменным\n",
    "    'min_samples_leaf': [1, 2, 3]  # Оставляем неизменным\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "### **2. Сужаем диапазон, если найдено устойчивое значение**\n",
    "Если по результатам `GridSearchCV` гиперпараметр стабильно оказывается, например, в середине диапазона, его можно зафиксировать или уменьшить диапазон для дальнейших оптимизаций. Это ускорит процесс подбора.\n",
    "\n",
    "#### Пример:\n",
    "Если после первого поиска `min_samples_leaf=2` везде показывает себя лучшим, диапазон можно зафиксировать:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  \n",
    "    'max_depth': [20, 30, 40],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [2]  # Фиксируем\n",
    "}\n",
    "```\n",
    "---\n",
    "### **3. Постепенная оптимизация**\n",
    "Для сложных моделей и большого количества гиперпараметров (как в `XGBoost` или `RandomForest`) иногда разумно не оптимизировать все сразу, а поэтапно. Например:\n",
    "- Сначала подбираете оптимальный диапазон для **важных параметров** (например, `max_depth` и `n_estimators`).\n",
    "- Затем фиксируете их и уточняете остальные параметры.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Пример кода**\n",
    "\n",
    "```python\n",
    "# Первый этап: ищем max_depth\n",
    "param_grid_stage_1 = {\n",
    "    'n_estimators': [100],  # Фиксируем\n",
    "    'max_depth': [10, 20, 30, 40, 50],  # Расширили диапазон\n",
    "    'min_samples_split': [5],  # Фиксируем\n",
    "    'min_samples_leaf': [2]  # Фиксируем\n",
    "}\n",
    "\n",
    "grid_search_stage_1 = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_stage_1,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_stage_1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучший max_depth:\", grid_search_stage_1.best_params_['max_depth'])\n",
    "\n",
    "# Второй этап: уточняем другие параметры\n",
    "best_max_depth = grid_search_stage_1.best_params_['max_depth']\n",
    "\n",
    "param_grid_stage_2 = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [best_max_depth],  # Фиксируем найденное значение\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search_stage_2 = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_stage_2,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_stage_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры:\", grid_search_stage_2.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Итог**\n",
    "1. **Расширяйте интервал только для тех гиперпараметров, которые достигают границ.**\n",
    "2. Оставляйте диапазоны других параметров неизменными.\n",
    "3. Используйте пошаговую оптимизацию для сложных моделей.\n",
    "4. После нахождения оптимальных значений проверьте их на тестовой выборке, чтобы убедиться, что модель действительно улучшилась. \n",
    "\n",
    "### **Результат:**\n",
    "Вы получите точные оптимальные значения гиперпараметров, избегая лишней вычислительной нагрузки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759c666-5834-4bc0-af09-a552facbe57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
