{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9b92f6-2eef-43fc-82e0-b73047c3e4db",
   "metadata": {},
   "source": [
    "### **1. Эффективно ли комбинировать CatBoost, XGBoost и LightGBM, если они из одного семейства?**\n",
    "\n",
    "CatBoost, XGBoost и LightGBM действительно относятся к одному семейству градиентного бустинга. Но это не означает, что их комбинация неэффективна. Они используют разные подходы в обучении (например, CatBoost хорошо работает с категориальными признаками, LightGBM оптимизирован по скорости, а XGBoost часто показывает лучшую точность на табличных данных). Комбинирование этих моделей может быть полезным, если они:\n",
    "- Переобучаются на разных признаках.\n",
    "- Имеют разную структуру ошибок.\n",
    "- Слегка по-разному интерпретируют данные.\n",
    "\n",
    "Однако в ансамблях действительно полезно комбинировать модели из **разных семейств**, например:\n",
    "- **CatBoost** (градиентный бустинг),\n",
    "- **SVM** (методы на основе опорных векторов),\n",
    "- **LinearRegression** (линейные модели),\n",
    "- **KNN** (алгоритмы на основе ближайших соседей).\n",
    "\n",
    "Эти модели изучают данные с разных сторон и комбинируют их сильные стороны. \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Какой алгоритм лучше использовать в качестве мета-алгоритма?**\n",
    "\n",
    "Мета-алгоритм (или модель второго уровня) обучается на предсказаниях базовых моделей. Хорошими вариантами могут быть:\n",
    "- **Линейная регрессия** или **логистическая регрессия** (если данные достаточно простые и предсказания линейно зависимы).\n",
    "- **CatBoost/XGBoost/LightGBM** для сложных задач с нелинейными зависимостями.\n",
    "- **Neural Networks** для обработки сложных зависимостей, если данных достаточно много.\n",
    "\n",
    "**Как выбирать?**\n",
    "- Если данные небольшие — попробуй линейные модели (они быстрее).\n",
    "- Если данных больше, стоит рассмотреть более мощные модели, такие как бустинг.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Чем отличаются Stacking и Blending?**\n",
    "\n",
    "| **Метод**     | **Принцип работы**                                                                                          | **Преимущества**                                                        | **Недостатки**                                          |\n",
    "|----------------|-----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|--------------------------------------------------------|\n",
    "| **Stacking**   | Использует мета-алгоритм, обучающийся на предсказаниях базовых моделей, созданных на всей тренировочной выборке. | - Учитывает зависимости между предсказаниями моделей. <br>- Высокая точность. | - Более сложная реализация. <br>- Требует разделения данных на фолды. |\n",
    "| **Blending**   | Использует простую линейную комбинацию или взвешенное усреднение предсказаний базовых моделей.              | - Простой в реализации. <br>- Не требует кросс-валидации.              | - Менее точный, так как игнорирует зависимости.         |\n",
    "\n",
    "Blending проще, но менее точен. Если у тебя есть достаточные вычислительные мощности и время, **Stacking** чаще дает лучшие результаты.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Можно ли делать Stacking глубже?**\n",
    "\n",
    "Да, можно углублять Stacking, создавая многоуровневые ансамбли. Например:\n",
    "- На первом уровне: **CatBoost**, **SVM**, **LinearRegression**.\n",
    "- На втором уровне: **CatBoost** как мета-алгоритм.\n",
    "- Далее: результаты этого ансамбля можно стекать с другими моделями (например, **RandomForest**, **Neural Network**).\n",
    "\n",
    "Это называется **глубоким стэкингом**. Но тут есть нюансы:\n",
    "1. **Увеличение сложности:** Глубокие ансамбли сложно отлаживать и интерпретировать.\n",
    "2. **Риск переобучения:** Если уровней слишком много, можно потерять обобщающую способность модели.\n",
    "3. **Требовательность к ресурсам:** Углубленный стэкинг требует больших вычислительных мощностей.\n",
    "\n",
    "---\n",
    "\n",
    "### **Резюме**\n",
    "1. **Можно комбинировать как модели одного семейства, так и разных классов.** Разные классы дают больше разнообразия, но даже модели одного семейства могут работать по-разному.\n",
    "2. **Используй Stacking для точности, Blending — для простоты.**\n",
    "3. **Углубленный Stacking возможен, но требует аккуратной настройки.** Убедись, что переобучение под контролем.\n",
    "4. Экспериментируй с гиперпараметрами и составом ансамбля для поиска оптимального подхода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127047a-db94-4021-81b0-0f38ec389c91",
   "metadata": {},
   "source": [
    "### **5. Пример глубокого Stacking на Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a171dd-8f04-4d79-9448-713557426f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Генерация данных\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Первый уровень моделей\n",
    "base_models = [\n",
    "    ('catboost', CatBoostRegressor(verbose=0)),\n",
    "    ('svm', SVR()),\n",
    "    ('linear', LinearRegression())\n",
    "]\n",
    "\n",
    "# Первый уровень стэкинга\n",
    "first_level = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "first_level.fit(X_train, y_train)\n",
    "\n",
    "# Второй уровень: стекуем результат с RandomForest\n",
    "final_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('stacking', first_level),\n",
    "        ('random_forest', RandomForestRegressor(random_state=42))\n",
    "    ],\n",
    "    final_estimator=CatBoostRegressor(verbose=0)\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Прогноз и оценка\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7abd1-b154-4dee-9f64-d36b4af73569",
   "metadata": {},
   "source": [
    "### **6. Расширенный стеккинг (stacked generalization with raw features), Out-of-Fold (OOF)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315b5ab-03c5-44ef-8d76-b8efc6812306",
   "metadata": {},
   "source": [
    "Да, логика в вашем подходе есть. Добавление исходных признаков к метамодели в стекинге – вполне валидная и часто применяемая стратегия. Это называется Stacked Regression с использованием исходных признаков (Stacked Regressors with Original Features).\n",
    "\n",
    "Почему это может быть полезно:\n",
    "\n",
    "•  Метамодель получает больше контекста: Прогнозы моделей первого уровня (Catboost, XGBoost, KNN) могут быть сложными и не всегда легко интерпретируемыми. Добавление исходных признаков позволяет метамодели увидеть более прямую связь между характеристиками квартиры и ценой.\n",
    "•  Исправление систематических ошибок: Если какая-то из базовых моделей систематически недооценивает или переоценивает квартиры определенного типа (например, квартиры в новостройках), метамодель с исходными признаками может это компенсировать.\n",
    "•  Более точная калибровка: Метамодель может лучше откалибровать прогнозы базовых моделей, особенно если они имеют тенденцию быть слишком уверенными или слишком неуверенными в своих предсказаниях.\n",
    "\n",
    "Как избежать утечки информации (data leakage):\n",
    "\n",
    "Самая главная проблема в стекинге - это утечка данных, которая приводит к переобучению и плохой обобщающей способности на новых данных. Вот как её предотвратить:\n",
    "\n",
    "1. Правильное разделение данных:\n",
    "  •  Первый уровень (обучение базовых моделей): Обучите Catboost, XGBoost и KNN на тренировочном наборе данных. Важно, чтобы этот тренировочный набор был отделен от данных, используемых для обучения метамодели.\n",
    "  •  Второй уровень (обучение метамодели):\n",
    "    *  Сгенерируйте прогнозы Out-of-Fold (OOF) на тренировочном наборе: Вместо того чтобы просто предсказывать на тренировочном наборе, используйте кросс-валидацию (например, K-fold) на тренировочном наборе. Для каждого фолда:\n",
    "      1. Обучите базовые модели (Catboost, XGBoost, KNN) на всех фолдах, кроме текущего.\n",
    "      2. Предскажите стоимость на фолде, который был исключен из обучения.\n",
    "    *  После завершения кросс-валидации у вас будет набор OOF прогнозов для каждой квартиры в тренировочном наборе. Эти OOF прогнозы используются в качестве признаков для метамодели.\n",
    "    *  Важно: Исходные признаки квартир (площадь, этаж и т.д.) также должны быть присоединены к этим OOF прогнозам при обучении метамодели.\n",
    "  •  Тестовый набор:\n",
    "    1. Обучите базовые модели на всем тренировочном наборе.\n",
    "    2. Предскажите стоимость квартир на тестовом наборе каждой базовой моделью.\n",
    "    3. Объедините эти прогнозы с исходными признаками тестового набора.\n",
    "    4. Используйте метамодель, обученную на OOF прогнозах и исходных признаках тренировочного набора, для предсказания стоимости на тестовом наборе.\n",
    "\n",
    "2. Кросс-валидация для метамодели: Даже при использовании OOF прогнозов, полезно использовать кросс-валидацию при обучении метамодели. Это поможет оценить стабильность метамодели и избежать переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2aad71-937d-48f1-ae9d-128b54599182",
   "metadata": {},
   "source": [
    "Прогнозы Out-of-Fold (OOF) — это прогнозы, полученные с использованием кросс-валидации, которые позволяют избежать утечки данных при обучении метамодели в стекинге. Давайте разберем это подробно:\n",
    "\n",
    "Проблема утечки данных в стекинге (и почему нужны OOF прогнозы):\n",
    "\n",
    "Представьте, что вы хотите построить модель, которая предсказывает вероятность того, что клиент покинет компанию (отток клиентов). Вы обучили несколько хороших моделей (например, логистическую регрессию, случайный лес, градиентный бустинг) и теперь хотите объединить их прогнозы, чтобы получить еще более точную модель.\n",
    "\n",
    "•  Наивный подход (с утечкой данных): Вы берете весь свой тренировочный набор, обучаете на нем каждую из своих базовых моделей, а затем используете эти обученные модели для предсказания на том же тренировочном наборе. Затем вы берете эти прогнозы и используете их в качестве признаков для обучения метамодели (например, линейной регрессии). Это плохо!\n",
    "\n",
    "Почему это плохо? Потому что каждая базовая модель \"видела\" данные, на которых она делала прогнозы. Это означает, что прогнозы базовых моделей будут переобучены на тренировочных данных. Метамодель, которая обучается на этих переобученных прогнозах, также будет переобучена и, скорее всего, покажет плохие результаты на новых, невиданных данных. Это называется утечкой данных (data leakage).\n",
    "\n",
    "Out-of-Fold (OOF) прогнозы: Решение проблемы утечки данных\n",
    "\n",
    "OOF прогнозы — это способ создания прогнозов для тренировочного набора, при котором каждая базовая модель делает прогноз для конкретной строки тренировочного набора, не видя эту строку во время обучения. Это достигается с помощью кросс-валидации.\n",
    "\n",
    "Как это работает (пошагово):\n",
    "\n",
    "1. Разделите тренировочный набор на K частей (фолдов). Например, K=5.\n",
    "2. Для каждого фолда (от 1 до K):\n",
    "  •  Обучите базовые модели (логистическую регрессию, случайный лес, градиентный бустинг и т. д.) на всех фолдах, кроме текущего. Например, если текущий фолд — 1, вы обучаете модели на фолдах 2, 3, 4 и 5.\n",
    "  •  Сделайте прогнозы только на текущем фолде. Используйте обученные модели для предсказания целевой переменной для строк в фолде 1.\n",
    "3. Повторите шаг 2 для каждого фолда. В конце этого процесса каждая строка в тренировочном наборе получит прогноз от каждой базовой модели. Но важно то, что этот прогноз был сделан моделью, которая не обучалась на этой конкретной строке.\n",
    "4. Соберите все прогнозы: У вас будет набор прогнозов OOF для каждой базовой модели. Эти OOF прогнозы теперь можно безопасно использовать в качестве признаков для обучения метамодели.\n",
    "\n",
    "Почему OOF прогнозы предотвращают утечку данных:\n",
    "\n",
    "Потому что каждая базовая модель делает прогноз для каждой строки в тренировочном наборе, не видя эту строку во время обучения. Это имитирует ситуацию, когда модель делает прогноз на новых, невиданных данных. Это гарантирует, что метамодель не будет обучаться на переобученных прогнозах и будет лучше обобщать на новые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed4090fb-548a-4b55-943e-0fe25cfedecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Установите seed для воспроизводимости результатов\n",
    "np.random.seed(42)\n",
    "\n",
    "# Количество квартир\n",
    "n_samples = 1000\n",
    "\n",
    "# Генерация признаков\n",
    "data = pd.DataFrame({\n",
    "    'area': np.random.randint(30, 120, n_samples),  # Площадь (кв.м)\n",
    "    'floor': np.random.randint(1, 25, n_samples),   # Этаж\n",
    "    'building_age': np.random.randint(1, 50, n_samples), # Возраст дома (лет)\n",
    "    'distance_to_metro': np.random.randint(500, 5000, n_samples), # Расстояние до метро (м)\n",
    "    'latitude': np.random.uniform(55.6, 55.9, n_samples), # Широта (Москва, пример)\n",
    "    'longitude': np.random.uniform(37.4, 37.8, n_samples),# Долгота (Москва, пример)\n",
    "    'condition': np.random.choice(['good', 'average', 'bad'], n_samples),  # Состояние квартиры\n",
    "    'building_type': np.random.choice(['brick', 'panel', 'monolith'], n_samples), # Тип дома\n",
    "    'rooms': np.random.randint(1, 4, n_samples)  # Количество комнат\n",
    "})\n",
    "\n",
    "# Закодируем категориальные признаки (condition и building_type)\n",
    "data = pd.get_dummies(data, columns=['condition', 'building_type'], drop_first=True)\n",
    "\n",
    "# Создадим целевую переменную (цена) на основе признаков с добавлением шума\n",
    "# Это пример, коэффициенты можно менять, чтобы модель была сложнее\n",
    "price = (\n",
    "    100000 * data['area'] +\n",
    "    1000 * data['floor'] -\n",
    "    500 * data['building_age'] -\n",
    "    20 * data['distance_to_metro'] +\n",
    "    100000 * data['rooms'] +\n",
    "    50000 * data['condition_good'] +\n",
    "    80000 * data['building_type_monolith'] +\n",
    "    60000 * data['building_type_panel'] +\n",
    "    np.random.normal(0, 500000, n_samples)  # Добавляем случайный шум\n",
    ")\n",
    "\n",
    "# Обеспечим, чтобы цена была положительной\n",
    "price = np.maximum(price, 1000000) #Минимальная цена квартиры 1 млн\n",
    "\n",
    "data['price'] = price\n",
    "\n",
    "# Разделим на X и y\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56e542e6-2e98-49f0-87c1-8bfb5f96d9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age</th>\n",
       "      <th>distance_to_metro</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rooms</th>\n",
       "      <th>condition_bad</th>\n",
       "      <th>condition_good</th>\n",
       "      <th>building_type_monolith</th>\n",
       "      <th>building_type_panel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2590</td>\n",
       "      <td>55.738515</td>\n",
       "      <td>37.454184</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4169</td>\n",
       "      <td>55.876298</td>\n",
       "      <td>37.492590</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4772</td>\n",
       "      <td>55.808379</td>\n",
       "      <td>37.747364</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>2133</td>\n",
       "      <td>55.818694</td>\n",
       "      <td>37.770586</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2017</td>\n",
       "      <td>55.858507</td>\n",
       "      <td>37.567851</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1604</td>\n",
       "      <td>55.648906</td>\n",
       "      <td>37.722039</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3036</td>\n",
       "      <td>55.670144</td>\n",
       "      <td>37.738016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>4699</td>\n",
       "      <td>55.607112</td>\n",
       "      <td>37.558021</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>4354</td>\n",
       "      <td>55.850484</td>\n",
       "      <td>37.420505</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>3994</td>\n",
       "      <td>55.892407</td>\n",
       "      <td>37.560751</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  floor  building_age  distance_to_metro   latitude  longitude  \\\n",
       "0      81     11            12               2590  55.738515  37.454184   \n",
       "1      44      9             1               4169  55.876298  37.492590   \n",
       "2     101      5            20               4772  55.808379  37.747364   \n",
       "3      90     14            28               2133  55.818694  37.770586   \n",
       "4      50      3            43               2017  55.858507  37.567851   \n",
       "..    ...    ...           ...                ...        ...        ...   \n",
       "995    93      1            33               1604  55.648906  37.722039   \n",
       "996    51      5            17               3036  55.670144  37.738016   \n",
       "997    89     20            24               4699  55.607112  37.558021   \n",
       "998    93      8            34               4354  55.850484  37.420505   \n",
       "999   101     11            28               3994  55.892407  37.560751   \n",
       "\n",
       "     rooms  condition_bad  condition_good  building_type_monolith  \\\n",
       "0        1          False           False                   False   \n",
       "1        2          False            True                   False   \n",
       "2        1           True           False                    True   \n",
       "3        3          False           False                   False   \n",
       "4        2           True           False                    True   \n",
       "..     ...            ...             ...                     ...   \n",
       "995      2          False            True                   False   \n",
       "996      2           True           False                   False   \n",
       "997      2          False            True                   False   \n",
       "998      2          False            True                   False   \n",
       "999      1           True           False                    True   \n",
       "\n",
       "     building_type_panel  \n",
       "0                   True  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                   True  \n",
       "4                  False  \n",
       "..                   ...  \n",
       "995                False  \n",
       "996                False  \n",
       "997                 True  \n",
       "998                 True  \n",
       "999                False  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be5b1217-7614-47a8-b161-82e13860894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделяем данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5ca2cf7-4229-4c8f-999b-ee29179e1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Определите базовые модели\n",
    "catboost = cb.CatBoostRegressor(verbose=False)\n",
    "xgboost = xgb.XGBRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Определите метамодель\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Определите количество фолдов для кросс-валидации\n",
    "n_folds = 5\n",
    "\n",
    "# Создайте KFold объект\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Создайте массивы для хранения OOF прогнозов\n",
    "oof_catboost = np.zeros(len(X_train))\n",
    "oof_xgboost = np.zeros(len(X_train))\n",
    "oof_knn = np.zeros(len(X_train))\n",
    "\n",
    "val_idx = []\n",
    "\n",
    "# Цикл по фолдам\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Обучите базовые модели на тренировочном фолде\n",
    "    catboost.fit(X_tr, y_tr)\n",
    "    xgboost.fit(X_tr, y_tr)\n",
    "    knn.fit(X_tr, y_tr)\n",
    "\n",
    "    # Сделайте прогнозы на валидационном фолде\n",
    "    oof_catboost[val_index] = catboost.predict(X_val)\n",
    "    oof_xgboost[val_index] = xgboost.predict(X_val)\n",
    "    oof_knn[val_index] = knn.predict(X_val)\n",
    "\n",
    "    val_idx.append(val_index)\n",
    "\n",
    "# Создайте DataFrame с OOF прогнозами и исходными признаками\n",
    "meta_features = pd.DataFrame({\n",
    "                              'catboost': oof_catboost,\n",
    "                              'xgboost': oof_xgboost,\n",
    "                              'knn': oof_knn\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9251ead5-8a7a-4b16-8b87-5ee53ff87e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catboost</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.111898e+06</td>\n",
       "      <td>6850361.50</td>\n",
       "      <td>7.050429e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.418849e+06</td>\n",
       "      <td>4628059.50</td>\n",
       "      <td>6.516811e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.536954e+06</td>\n",
       "      <td>5179128.50</td>\n",
       "      <td>5.641945e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.126680e+07</td>\n",
       "      <td>11524882.00</td>\n",
       "      <td>1.063361e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.055839e+07</td>\n",
       "      <td>10574124.00</td>\n",
       "      <td>8.672891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.159889e+07</td>\n",
       "      <td>11701244.00</td>\n",
       "      <td>8.199318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>7.504467e+06</td>\n",
       "      <td>7520556.00</td>\n",
       "      <td>9.073351e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>3.499754e+06</td>\n",
       "      <td>3640001.75</td>\n",
       "      <td>5.807577e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7.669577e+06</td>\n",
       "      <td>7822871.00</td>\n",
       "      <td>7.664489e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>4.705315e+06</td>\n",
       "      <td>4115087.25</td>\n",
       "      <td>4.578677e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         catboost      xgboost           knn\n",
       "0    7.111898e+06   6850361.50  7.050429e+06\n",
       "1    4.418849e+06   4628059.50  6.516811e+06\n",
       "2    5.536954e+06   5179128.50  5.641945e+06\n",
       "3    1.126680e+07  11524882.00  1.063361e+07\n",
       "4    1.055839e+07  10574124.00  8.672891e+06\n",
       "..            ...          ...           ...\n",
       "795  1.159889e+07  11701244.00  8.199318e+06\n",
       "796  7.504467e+06   7520556.00  9.073351e+06\n",
       "797  3.499754e+06   3640001.75  5.807577e+06\n",
       "798  7.669577e+06   7822871.00  7.664489e+06\n",
       "799  4.705315e+06   4115087.25  4.578677e+06\n",
       "\n",
       "[800 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4e99762-4c2c-4697-8fb8-46b09fbb95c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  2,   7,  10,  23,  29,  30,  31,  33,  39,  49,  54,  63,  65,\n",
       "         66,  67,  72,  76,  77,  78,  81,  84,  86,  96,  97, 101, 109,\n",
       "        110, 118, 120, 137, 139, 155, 168, 174, 192, 198, 199, 204, 208,\n",
       "        209, 210, 211, 215, 218, 231, 235, 244, 250, 254, 260, 265, 266,\n",
       "        275, 281, 286, 294, 296, 302, 306, 314, 316, 323, 326, 327, 333,\n",
       "        336, 346, 352, 357, 360, 361, 365, 367, 368, 377, 383, 388, 393,\n",
       "        395, 398, 409, 422, 423, 425, 428, 432, 446, 456, 464, 481, 483,\n",
       "        486, 490, 506, 512, 513, 515, 519, 521, 525, 526, 529, 532, 533,\n",
       "        534, 537, 545, 568, 570, 578, 589, 591, 594, 595, 596, 604, 608,\n",
       "        610, 621, 622, 628, 635, 637, 640, 641, 644, 652, 655, 656, 658,\n",
       "        662, 666, 667, 670, 688, 692, 696, 705, 715, 719, 720, 721, 723,\n",
       "        738, 741, 744, 746, 750, 754, 758, 760, 764, 776, 777, 783, 786,\n",
       "        787, 795, 796, 798]),\n",
       " array([  6,  11,  18,  24,  28,  41,  42,  43,  44,  51,  55,  56,  60,\n",
       "         61,  69,  70,  73,  74,  79,  82,  83,  89,  90,  92, 104, 108,\n",
       "        114, 131, 132, 133, 135, 136, 140, 145, 148, 158, 163, 164, 165,\n",
       "        167, 176, 177, 178, 181, 182, 193, 196, 212, 213, 220, 223, 227,\n",
       "        234, 239, 247, 248, 259, 264, 285, 290, 291, 292, 299, 300, 309,\n",
       "        311, 319, 328, 329, 331, 332, 334, 342, 344, 350, 351, 355, 356,\n",
       "        363, 375, 380, 381, 382, 394, 404, 405, 411, 412, 424, 426, 431,\n",
       "        433, 436, 440, 442, 443, 444, 447, 448, 450, 462, 467, 473, 479,\n",
       "        493, 494, 495, 497, 500, 501, 517, 518, 522, 527, 528, 530, 539,\n",
       "        549, 554, 559, 569, 575, 576, 582, 584, 586, 593, 603, 613, 615,\n",
       "        620, 625, 629, 631, 643, 650, 659, 664, 665, 673, 676, 689, 691,\n",
       "        703, 707, 710, 713, 724, 728, 730, 733, 734, 736, 743, 748, 749,\n",
       "        755, 761, 780, 790]),\n",
       " array([  0,   3,   9,  12,  15,  19,  22,  25,  38,  46,  50,  57,  59,\n",
       "         68,  75,  88,  93, 100, 107, 113, 116, 117, 124, 125, 126, 141,\n",
       "        142, 144, 149, 153, 154, 169, 172, 173, 175, 179, 184, 185, 188,\n",
       "        195, 203, 221, 222, 228, 236, 237, 238, 245, 249, 256, 257, 261,\n",
       "        263, 268, 271, 272, 274, 277, 278, 280, 284, 287, 289, 298, 304,\n",
       "        305, 307, 310, 312, 318, 320, 321, 324, 335, 338, 340, 341, 349,\n",
       "        353, 354, 359, 362, 369, 370, 371, 390, 396, 399, 407, 408, 416,\n",
       "        417, 420, 429, 430, 434, 439, 445, 449, 451, 453, 457, 465, 477,\n",
       "        478, 482, 485, 487, 499, 507, 514, 523, 531, 541, 543, 544, 547,\n",
       "        548, 551, 552, 567, 571, 580, 583, 585, 597, 599, 602, 611, 624,\n",
       "        626, 634, 638, 648, 649, 653, 660, 668, 671, 672, 690, 695, 697,\n",
       "        714, 718, 726, 735, 737, 739, 745, 756, 762, 765, 766, 770, 784,\n",
       "        789, 791, 794, 799]),\n",
       " array([  5,   8,  16,  17,  26,  36,  37,  45,  48,  53,  94, 103, 111,\n",
       "        112, 115, 119, 122, 123, 127, 129, 143, 146, 147, 150, 151, 152,\n",
       "        157, 162, 171, 180, 183, 186, 190, 194, 197, 202, 207, 219, 224,\n",
       "        225, 226, 229, 232, 233, 246, 253, 255, 258, 262, 267, 279, 282,\n",
       "        283, 293, 297, 301, 303, 317, 322, 325, 347, 348, 358, 364, 373,\n",
       "        374, 376, 384, 386, 400, 402, 403, 410, 414, 415, 419, 421, 437,\n",
       "        438, 441, 452, 463, 468, 469, 470, 472, 480, 488, 496, 503, 505,\n",
       "        509, 511, 516, 535, 536, 538, 542, 550, 557, 558, 572, 579, 581,\n",
       "        587, 588, 590, 598, 601, 605, 606, 607, 609, 616, 617, 618, 623,\n",
       "        627, 630, 632, 633, 636, 639, 651, 657, 669, 675, 677, 682, 683,\n",
       "        684, 693, 694, 698, 708, 709, 711, 712, 717, 725, 727, 729, 731,\n",
       "        732, 742, 751, 753, 757, 759, 763, 768, 771, 772, 773, 774, 775,\n",
       "        779, 781, 785, 792]),\n",
       " array([  1,   4,  13,  14,  20,  21,  27,  32,  34,  35,  40,  47,  52,\n",
       "         58,  62,  64,  71,  80,  85,  87,  91,  95,  98,  99, 102, 105,\n",
       "        106, 121, 128, 130, 134, 138, 156, 159, 160, 161, 166, 170, 187,\n",
       "        189, 191, 200, 201, 205, 206, 214, 216, 217, 230, 240, 241, 242,\n",
       "        243, 251, 252, 269, 270, 273, 276, 288, 295, 308, 313, 315, 330,\n",
       "        337, 339, 343, 345, 366, 372, 378, 379, 385, 387, 389, 391, 392,\n",
       "        397, 401, 406, 413, 418, 427, 435, 454, 455, 458, 459, 460, 461,\n",
       "        466, 471, 474, 475, 476, 484, 489, 491, 492, 498, 502, 504, 508,\n",
       "        510, 520, 524, 540, 546, 553, 555, 556, 560, 561, 562, 563, 564,\n",
       "        565, 566, 573, 574, 577, 592, 600, 612, 614, 619, 642, 645, 646,\n",
       "        647, 654, 661, 663, 674, 678, 679, 680, 681, 685, 686, 687, 699,\n",
       "        700, 701, 702, 704, 706, 716, 722, 740, 747, 752, 767, 769, 778,\n",
       "        782, 788, 793, 797])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c479f059-8233-4d6d-873e-d41ef090b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объедините OOF прогнозы с исходными признаками\n",
    "X_train_ = X_train\n",
    "X_train_.reset_index(drop = True, inplace = True)\n",
    "meta_features = pd.concat([meta_features, X_train_], axis=1)\n",
    "\n",
    "# Обучите метамодель на OOF прогнозах и исходных признаках\n",
    "meta_model.fit(meta_features, y_train)\n",
    "\n",
    "# 1. Обучите базовые модели на всем тренировочном наборе\n",
    "catboost.fit(X_train, y_train)\n",
    "xgboost.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 2. Сделайте прогнозы на тестовом наборе\n",
    "test_catboost = catboost.predict(X_test)  # X_test - ваш тестовый набор\n",
    "test_xgboost = xgboost.predict(X_test)\n",
    "test_knn = knn.predict(X_test)\n",
    "\n",
    "# 3. Создайте DataFrame с прогнозами и исходными признаками тестового набора\n",
    "test_meta_features = pd.DataFrame({\n",
    "                                   'catboost': test_catboost,\n",
    "                                   'xgboost': test_xgboost,\n",
    "                                   'knn': test_knn\n",
    "                                 })\n",
    "\n",
    "X_test_ = X_test\n",
    "X_test_.reset_index(drop = True, inplace = True)\n",
    "test_meta_features = pd.concat([test_meta_features, X_test_], axis=1)\n",
    "\n",
    "# 4. Сделайте предсказания на тестовом наборе с помощью метамодели\n",
    "predictions = meta_model.predict(test_meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "276fe23a-3a95-46c7-ac67-42907f6b3390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6554218.87391458,  7601791.59477856,  9290475.15469377,\n",
       "       11735813.74102364,  3556886.8376087 ,  7048998.60414339,\n",
       "        3308298.83303774,  3779860.47576784, 11925078.58988766,\n",
       "        3547577.28422388,  5755742.61586154,  6349691.18537873,\n",
       "        7497037.67829323,  9288221.13878348,  8186938.91866433,\n",
       "        5859456.71270305,  6706741.77346121,  4319593.27192665,\n",
       "        4603559.94795701,  6046854.6611786 ,  9318266.18994587,\n",
       "       11757299.65772441,  4219259.02516267,  6665345.70292857,\n",
       "        5014454.70806822,  5031590.24952122, 10186479.00524811,\n",
       "        8180120.94247629,  8799360.03283724,  5171220.99113298,\n",
       "        5725659.9145285 ,  5738251.37570492,  5115437.24400549,\n",
       "        6046617.96478718,  5469130.26138715,  4381694.97759678,\n",
       "        5843045.7869966 ,  3666598.69530463,  8941889.49133173,\n",
       "        3701686.60246806,  7848179.84642658,  6060887.12059211,\n",
       "        8181255.44193326, 10416327.26614696,  5161881.00744631,\n",
       "        5631460.85865947,  9688075.10040128,  4799526.25939232,\n",
       "        9311417.87890497,  5457723.04300161,  7497583.96282943,\n",
       "       12143203.58292448,  3528327.3101274 ,  4695351.13691609,\n",
       "       10813549.24285088,  9131395.81696903,  9712406.86948029,\n",
       "        5410908.48702304,  8802778.18539862,  7437522.32801891,\n",
       "        4426858.18639483,  3459777.32045392, 11996250.93207863,\n",
       "        3124857.27464777,  7489103.72673353, 11272417.23957888,\n",
       "       10698977.31553024,  3353412.77324818,  3477878.50987605,\n",
       "       11677291.16220661,  9442980.48391969,  9614014.04831562,\n",
       "        8177225.57998225,  9640153.45372545,  7271107.16251375,\n",
       "        6456370.60031398,  7973728.7626786 ,  9526212.75022208,\n",
       "        4003068.07294627,  9056469.21114404,  9371579.72356312,\n",
       "        3606019.44455134,  8483398.5201587 ,  3193491.79224185,\n",
       "        5992201.60404669,  4351941.35339122,  9510822.7221672 ,\n",
       "       10915590.97248025,  8597687.75176848,  9558020.0168461 ,\n",
       "       10814710.80556537,  5999298.3701112 ,  3952568.589724  ,\n",
       "        9917178.98045854, 10475578.49859867, 11983032.22300947,\n",
       "        8390769.90740169, 11023940.92211732, 11073973.17100953,\n",
       "        3516483.74725445,  3299148.99822332,  5550427.04256579,\n",
       "        4035468.08373697,  7110010.83277465,  8816737.18685705,\n",
       "       11506441.43518903,  5817200.2460158 ,  6353780.41375915,\n",
       "        6035437.37226439,  3973770.4562455 , 11303510.66878883,\n",
       "        5095585.88243489,  9033972.04189812,  5074370.25642187,\n",
       "        7077240.4089257 ,  8825903.23975736,  3867791.39606784,\n",
       "        4483490.24007623,  8607948.51202031,  9862701.88360228,\n",
       "        4019177.34376828, 12155447.6663602 ,  8050170.33333381,\n",
       "        9077370.5163772 ,  6755242.00368286, 10102093.2839528 ,\n",
       "        4776675.00134216, 10649464.02077242,  5493029.90189018,\n",
       "        8599554.72346465,  9596319.55910755,  8140988.11761698,\n",
       "        9907907.70985414,  9437334.87224469,  5678707.64986586,\n",
       "       11308837.5604664 ,  4287685.57322575,  6061703.14686896,\n",
       "        5152415.26468523,  9432877.80814937, 10400898.26731434,\n",
       "        7020323.21678072,  9921474.91310746,  6677322.40718977,\n",
       "        6927551.11622697,  9180297.95204912,  9862075.03148521,\n",
       "        8323486.58882473,  5211450.33896195, 10043863.22451722,\n",
       "       11005853.57129074,  9143077.16117614, 10469903.66684946,\n",
       "        4025826.60713981,  3665034.32490631, 11646868.80373467,\n",
       "        5234457.51617938,  4028501.45952425,  7653790.42214339,\n",
       "       11399947.87032105,  6849370.49962167,  6936614.16589953,\n",
       "        8753757.89392399,  4715990.31915119,  3818292.88420931,\n",
       "        5506219.35908177,  8001272.17957557,  7582513.28327852,\n",
       "        3930268.46688814,  5992961.22505553,  6259040.06867524,\n",
       "        3561236.71362822,  3955756.63841963,  4101517.08510098,\n",
       "        6192759.28091247,  7320690.72561477,  5577994.21328599,\n",
       "       12031522.81897347, 10534342.087402  ,  5717215.34357893,\n",
       "        6428913.85909706,  3920798.81045643,  5022970.89920456,\n",
       "        7926057.51212662,  5888188.01129216, 12044961.09036102,\n",
       "        5520896.87852877,  6880443.63203735, 10162342.07741137,\n",
       "        3292550.74548572,  4228765.29571997,  7673931.430672  ,\n",
       "        3221928.04183926,  6912438.17090041,  7456169.68793472,\n",
       "        9000210.94804098,  7509399.71195163, 11745976.7453772 ,\n",
       "       10498926.86919382,  9506650.94675176])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52a1ef3d-3c70-4a53-b484-71f2e59d8a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521    6.637282e+06\n",
       "737    8.440091e+06\n",
       "740    9.027947e+06\n",
       "660    1.237589e+07\n",
       "411    3.748069e+06\n",
       "           ...     \n",
       "408    9.677073e+06\n",
       "332    7.761302e+06\n",
       "208    1.117080e+07\n",
       "613    1.115507e+07\n",
       "78     9.301880e+06\n",
       "Name: price, Length: 200, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9f0c3-c47f-42dd-9c7f-70b280c9958d",
   "metadata": {},
   "source": [
    "#### **Deep seek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376f23df-50eb-46ca-a3a3-9e8aa8da45d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Создаем искусственные данные\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Генерируем случайные значения для каждого фактора\n",
    "area = np.random.uniform(30, 150, n_samples)  # Площадь квартиры\n",
    "floor = np.random.randint(1, 20, n_samples)   # Этаж\n",
    "total_floors = np.random.randint(floor, floor + 10, n_samples)  # Этажность здания\n",
    "year_built = np.random.randint(1950, 2020, n_samples)  # Год постройки\n",
    "condition = np.random.choice(['good', 'average', 'bad'], n_samples)  # Состояние отделки\n",
    "\n",
    "# Приведение состояния к числовым значениям\n",
    "data = pd.DataFrame({\n",
    "    'area': area,\n",
    "    'floor': floor,\n",
    "    'total_floors': total_floors,\n",
    "    'year_built': year_built,\n",
    "    'condition': condition\n",
    "})\n",
    "\n",
    "# Приведение состояния к числовым значениям\n",
    "data['condition_numeric'] = data['condition'].map({'good': 3, 'average': 2, 'bad': 1})\n",
    "\n",
    "# Генерируем целевую переменную (цена квартиры) на основе факторов\n",
    "price = (\n",
    "    data['area'] * 1000 +\n",
    "    data['floor'] * 500 +\n",
    "    data['total_floors'] * 100 +\n",
    "    (2020 - data['year_built']) * 300 +\n",
    "    data['condition_numeric'] * 1000\n",
    ")\n",
    "data['price'] = price\n",
    "\n",
    "# Добавляем информацию о районе\n",
    "#districts = np.random.choice(['District1', 'District2', 'District3'], n_samples)  # Пример 3 района\n",
    "#data['district'] = districts\n",
    "\n",
    "# Добавляем координаты и расстояние до метро (искусственные данные)\n",
    "latitude = np.random.uniform(55.5, 56.0, n_samples)  # Пример координат широты\n",
    "longitude = np.random.uniform(37.0, 38.0, n_samples)  # Пример координат долготы\n",
    "distance_to_metro = np.random.uniform(1000, 5000, n_samples)  # Пример расстояния до метро\n",
    "\n",
    "data['latitude'] = latitude\n",
    "data['longitude'] = longitude\n",
    "data['distance_to_metro'] = distance_to_metro\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop(['price', 'condition'], axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем KFold для кросс-валидации\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Создаем массивы для мета-признаков\n",
    "catboost_meta_train = np.zeros((X_train.shape[0],))\n",
    "xgboost_meta_train = np.zeros((X_train.shape[0],))\n",
    "knn_meta_train = np.zeros((X_train.shape[0],))\n",
    "\n",
    "catboost_meta_test = np.zeros((X_test.shape[0],))\n",
    "xgboost_meta_test = np.zeros((X_test.shape[0],))\n",
    "knn_meta_test = np.zeros((X_test.shape[0],))\n",
    "\n",
    "# Обучаем основные модели и создаем мета-признаки\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    X_fold_train, X_fold_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_fold_train, y_fold_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    \n",
    "    # Обучаем CatBoost\n",
    "    catboost_model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='RMSE', verbose=0)\n",
    "    catboost_model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_valid, y_fold_valid), early_stopping_rounds=10, use_best_model=True)\n",
    "    catboost_predictions = catboost_model.predict(X_fold_valid)\n",
    "    catboost_meta_train[valid_index] = catboost_predictions\n",
    "    \n",
    "    # Обучаем XGBoost\n",
    "    xgboost_model = XGBRegressor(n_estimators=1000, learning_rate=0.1, max_depth=6, objective='reg:squarederror', random_state=42)\n",
    "    xgboost_model.fit(X_fold_train, y_fold_train)\n",
    "    xgboost_predictions = xgboost_model.predict(X_fold_valid)\n",
    "    xgboost_meta_train[valid_index] = xgboost_predictions\n",
    "    \n",
    "    # Обучаем KNN\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn_model.fit(X_fold_train, y_fold_train)\n",
    "    knn_predictions = knn_model.predict(X_fold_valid)\n",
    "    knn_meta_train[valid_index] = knn_predictions\n",
    "    \n",
    "    # Обучаем CatBoost на тестовых данных для финальных предсказаний\n",
    "    catboost_meta_test += catboost_model.predict(X_test) / kf.n_splits # усреднение, получаем прогноз и делим его на количество фолдов = 5\n",
    "    \n",
    "    # Обучаем XGBoost на тестовых данных для финальных предсказаний\n",
    "    xgboost_meta_test += xgboost_model.predict(X_test) / kf.n_splits  # усреднение\n",
    "    \n",
    "    # Обучаем KNN на тестовых данных для финальных предсказаний\n",
    "    knn_meta_test += knn_model.predict(X_test) / kf.n_splits          # усреднение\n",
    "\n",
    "# Создаем DataFrame с мета-признаками и оригинальными признаками для обучения метамодели\n",
    "meta_X_train = pd.DataFrame({\n",
    "                             'catboost': catboost_meta_train,\n",
    "                             'xgboost': xgboost_meta_train,\n",
    "                             'knn': knn_meta_train\n",
    "                           })\n",
    "meta_X_train = pd.concat([meta_X_train, X_train.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Создаем DataFrame с мета-признаками и оригинальными признаками для предсказания метамоделью\n",
    "meta_X_test = pd.DataFrame({\n",
    "                            'catboost': catboost_meta_test,\n",
    "                            'xgboost': xgboost_meta_test,\n",
    "                            'knn': knn_meta_test\n",
    "                        })\n",
    "meta_X_test = pd.concat([meta_X_test, X_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Обучаем метамодель (например, Ridge)\n",
    "meta_model = Ridge()\n",
    "meta_model.fit(meta_X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "final_predictions = meta_model.predict(meta_X_test)\n",
    "\n",
    "# Оцениваем модель\n",
    "mse = mean_squared_error(y_test, final_predictions)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b33587f-541b-4975-b86c-b2ffad622971",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=8]=\"  (0, 0)\t1.0\": Cannot convert obj   (0, 0)\t1.0 to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m_catboost.pyx:1228\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'csr_matrix'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m_catboost.pyx:2547\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:1230\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert obj   (0, 0)\t1.0 to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Обучаем CatBoost\u001b[39;00m\n\u001b[0;32m     91\u001b[0m catboost_model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m \u001b[43mcatboost_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_fold_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m catboost_predictions \u001b[38;5;241m=\u001b[39m catboost_model\u001b[38;5;241m.\u001b[39mpredict(X_fold_valid)\n\u001b[0;32m     94\u001b[0m catboost_meta_train[valid_index] \u001b[38;5;241m=\u001b[39m catboost_predictions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:2395\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2395\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2405\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2406\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:2275\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   2272\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2273\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2275\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m \u001b[43m_build_train_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2276\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2277\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_pool\u001b[38;5;241m.\u001b[39mis_empty_:\n\u001b[0;32m   2279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:1513\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1513\u001b[0m     train_pool \u001b[38;5;241m=\u001b[39m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_pool\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:855\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[0;32m    850\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    852\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    853\u001b[0m             )\n\u001b[1;32m--> 855\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:1491\u001b[0m, in \u001b[0;36mPool._init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[1;32m-> 1491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_catboost.pyx:4339\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4391\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4200\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:3127\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:2591\u001b[0m, in \u001b[0;36m_catboost.create_num_factor_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:2549\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=8]=\"  (0, 0)\t1.0\": Cannot convert obj   (0, 0)\t1.0 to float"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Создаем искусственные данные\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Генерируем случайные значения для каждого фактора\n",
    "area = np.random.uniform(30, 150, n_samples)  # Площадь квартиры\n",
    "floor = np.random.randint(1, 20, n_samples)   # Этаж\n",
    "total_floors = np.random.randint(floor, floor + 10, n_samples)  # Этажность здания\n",
    "year_built = np.random.randint(1950, 2020, n_samples)  # Год постройки\n",
    "condition = np.random.choice(['good', 'average', 'bad'], n_samples)  # Состояние отделки\n",
    "\n",
    "# Приведение состояния к числовым значениям\n",
    "data = pd.DataFrame({\n",
    "    'area': area,\n",
    "    'floor': floor,\n",
    "    'total_floors': total_floors,\n",
    "    'year_built': year_built,\n",
    "    'condition': condition\n",
    "})\n",
    "\n",
    "# Приведение состояния к числовым значениям\n",
    "data['condition_numeric'] = data['condition'].map({'good': 3, 'average': 2, 'bad': 1})\n",
    "\n",
    "# Генерируем целевую переменную (цена квартиры) на основе факторов\n",
    "price = (\n",
    "    data['area'] * 1000 +\n",
    "    data['floor'] * 500 +\n",
    "    data['total_floors'] * 100 +\n",
    "    (2020 - data['year_built']) * 300 +\n",
    "    data['condition_numeric'] * 1000\n",
    ")\n",
    "data['price'] = price\n",
    "\n",
    "# Добавляем информацию о районе\n",
    "districts = np.random.choice(['District1', 'District2', 'District3'], n_samples)  # Пример 3 района\n",
    "data['district'] = districts\n",
    "\n",
    "# Добавляем координаты и расстояние до метро (искусственные данные)\n",
    "latitude = np.random.uniform(55.5, 56.0, n_samples)  # Пример координат широты\n",
    "longitude = np.random.uniform(37.0, 38.0, n_samples)  # Пример координат долготы\n",
    "distance_to_metro = np.random.uniform(1000, 5000, n_samples)  # Пример расстояния до метро\n",
    "\n",
    "data['latitude'] = latitude\n",
    "data['longitude'] = longitude\n",
    "data['distance_to_metro'] = distance_to_metro\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop(['price', 'condition'], axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обработка категориальных признаков\n",
    "encoder = OneHotEncoder()\n",
    "district_encoded = encoder.fit_transform(X_train[['district']])\n",
    "district_encoded_test = encoder.transform(X_test[['district']])\n",
    "\n",
    "# Добавляем закодированные признаки в DataFrame\n",
    "X_train_encoded = pd.concat([X_train.drop('district', axis=1).reset_index(drop=True), pd.DataFrame(district_encoded)], axis=1)\n",
    "X_test_encoded = pd.concat([X_test.drop('district', axis=1).reset_index(drop=True), pd.DataFrame(district_encoded_test)], axis=1)\n",
    "\n",
    "# Создаем KFold для кросс-валидации\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Создаем массивы для мета-признаков\n",
    "catboost_meta_train = np.zeros((X_train_encoded.shape[0],))\n",
    "xgboost_meta_train = np.zeros((X_train_encoded.shape[0],))\n",
    "knn_meta_train = np.zeros((X_train_encoded.shape[0],))\n",
    "\n",
    "catboost_meta_test = np.zeros((X_test_encoded.shape[0],))\n",
    "xgboost_meta_test = np.zeros((X_test_encoded.shape[0],))\n",
    "knn_meta_test = np.zeros((X_test_encoded.shape[0],))\n",
    "\n",
    "# Обучаем основные модели и создаем мета-признаки\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train_encoded)):\n",
    "    X_fold_train, X_fold_valid = X_train_encoded.iloc[train_index], X_train_encoded.iloc[valid_index]\n",
    "    y_fold_train, y_fold_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    \n",
    "    # Обучаем CatBoost\n",
    "    catboost_model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='RMSE', verbose=0)\n",
    "    catboost_model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_valid, y_fold_valid), early_stopping_rounds=10, use_best_model=True)\n",
    "    catboost_predictions = catboost_model.predict(X_fold_valid)\n",
    "    catboost_meta_train[valid_index] = catboost_predictions\n",
    "    \n",
    "    # Обучаем XGBoost\n",
    "    xgboost_model = XGBRegressor(n_estimators=1000, learning_rate=0.1, max_depth=6, objective='reg:squarederror', random_state=42)\n",
    "    xgboost_model.fit(X_fold_train, y_fold_train)\n",
    "    xgboost_predictions = xgboost_model.predict(X_fold_valid)\n",
    "    xgboost_meta_train[valid_index] = xgboost_predictions\n",
    "    \n",
    "    # Обучаем KNN\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn_model.fit(X_fold_train, y_fold_train)\n",
    "    knn_predictions = knn_model.predict(X_fold_valid)\n",
    "    knn_meta_train[valid_index] = knn_predictions\n",
    "    \n",
    "    # Обучаем CatBoost на тестовых данных для финальных предсказаний\n",
    "    catboost_meta_test += catboost_model.predict(X_test_encoded) / kf.n_splits\n",
    "    \n",
    "    # Обучаем XGBoost на тестовых данных для финальных предсказаний\n",
    "    xgboost_meta_test += xgboost_model.predict(X_test_encoded) / kf.n_splits\n",
    "    \n",
    "    # Обучаем KNN на тестовых данных для финальных предсказаний\n",
    "    knn_meta_test += knn_model.predict(X_test_encoded) / kf.n_splits\n",
    "\n",
    "# Создаем DataFrame с мета-признаками и оригинальными признаками для обучения метамодели\n",
    "meta_X_train = pd.DataFrame({\n",
    "    'catboost': catboost_meta_train,\n",
    "    'xgboost': xgboost_meta_train,\n",
    "    'knn': knn_meta_train\n",
    "})\n",
    "meta_X_train = pd.concat([meta_X_train, X_train_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Создаем DataFrame с мета-признаками и оригинальными признаками для предсказания метамоделью\n",
    "meta_X_test = pd.DataFrame({\n",
    "    'catboost': catboost_meta_test,\n",
    "    'xgboost': xgboost_meta_test,\n",
    "    'knn': knn_meta_test\n",
    "})\n",
    "meta_X_test = pd.concat([meta_X_test, X_test_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Обучаем метамодель (например, Ridge)\n",
    "meta_model = Ridge()\n",
    "meta_model.fit(meta_X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "final_predictions = meta_model.predict(meta_X_test)\n",
    "\n",
    "# Оцениваем модель\n",
    "mse = mean_squared_error(y_test, final_predictions)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51886b51-6320-4d99-bd1d-34e7e2ccaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Определяем параметры для подбора\n",
    "param_grid = {\n",
    "    'iterations': [1000],\n",
    "    'learning_rate': [0.1, 0.05],\n",
    "    'depth': [6, 8],\n",
    "    'l2_leaf_reg': [3, 5],\n",
    "    'early_stopping_rounds': [10]\n",
    "}\n",
    "\n",
    "# Создаем модель CatBoost\n",
    "catboost_model = CatBoostRegressor(loss_function='RMSE', verbose=0)\n",
    "\n",
    "# Используем GridSearchCV для подбора гиперпараметров\n",
    "grid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Лучшие параметры для CatBoost: {best_params}\")\n",
    "\n",
    "# Обучаем лучшую модель CatBoost\n",
    "best_catboost_model = CatBoostRegressor(**best_params, loss_function='RMSE', verbose=0)\n",
    "best_catboost_model.fit(X_train_encoded, y_train, eval_set=(X_test_encoded, y_test), early_stopping_rounds=10, use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4e0d5-4868-4493-b73b-edfd54bf7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Определяем параметры для подбора\n",
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'learning_rate': [0.1, 0.05],\n",
    "    'max_depth': [6, 8],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Создаем модель XGBoost\n",
    "xgboost_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Используем GridSearchCV для подбора гиперпараметров\n",
    "grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Лучшие параметры для XGBoost: {best_params}\")\n",
    "\n",
    "# Обучаем лучшую модель XGBoost\n",
    "best_xgboost_model = XGBRegressor(**best_params, objective='reg:squarederror', random_state=42)\n",
    "best_xgboost_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420822c-0900-45ee-9da9-20693eb3067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Определяем параметры для подбора\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Создаем модель KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Используем GridSearchCV для подбора гиперпараметров\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Лучшие параметры для KNN: {best_params}\")\n",
    "\n",
    "# Обучаем лучшую модель KNN\n",
    "best_knn_model = KNeighborsRegressor(**best_params)\n",
    "best_knn_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab6109-89df-4c00-b251-90b5fb916c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
