{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25f33a4-1868-483e-88ef-4f1e8e9b6605",
   "metadata": {},
   "source": [
    "Доверительные интервалы\n",
    "\n",
    "1. Мишень — это истинное значение чего-то, что мы пытаемся измерить (например, средняя цена за квадратный метр всех квартир в городе). Мы не знаем, где точно находится \"центр мишени\", но хотим его оценить.\n",
    "2. Вы делаете несколько выстрелов (собираете данные, например, цены за квадратный метр из выборки квартир). Ваши выстрелы не все точно в центре, они рассеяны вокруг него.\n",
    "3. Среднее значение ваших выстрелов (выборочное среднее) — это наша оценка положения \"центра мишени\". Это наша лучшая попытка угадать, где находится истинное значение, но это всего лишь оценка, и она может быть неточной.\n",
    "\n",
    "Теперь представьте, что мы хотим не только сказать, где примерно находится центр, но и показать, насколько мы уверены в этой оценке. Вот тут и приходит на помощь доверительный интервал.\n",
    "\n",
    "Что такое доверительный интервал?\n",
    "\n",
    "•  Доверительный интервал — это диапазон значений, вокруг нашего среднего, в котором с определенной вероятностью находится истинное значение. Это не конкретное значение, а целый интервал, показывающий насколько мы уверены в том, что истинное значение находится где-то в нем.\n",
    "•  Это \"ширина\" нашей уверенности. Чем шире интервал, тем менее точная наша оценка, но тем более мы уверены, что истинное значение \"где-то там\". Узкий интервал говорит о более точной оценке, но наша уверенность может быть меньше.\n",
    "\n",
    "Аналогия с мишенью:\n",
    "\n",
    "1. Представьте, что вы стреляете много раз, не один раз, а множество, каждый раз делаете свою выборку и по ней оцениваете центр мишени.\n",
    "2. Теперь для каждой выборки мы строим такой доверительный интервал.\n",
    "3. 95%-ный доверительный интервал означает, что если бы мы стреляли (брали выборки и строили интервалы) 100 раз, то примерно в 95 из этих случаев построенный интервал поймал бы истинный центр мишени. Другими словами, есть 95% вероятность, что истинное значение находится где-то в границах интервала, который мы построили.\n",
    "4. Оставшиеся 5 интервалов не поймают истинный центр. Мы не знаем, попался нам интервал, который \"поймал\" истину, или нет. Это важно понимать.\n",
    "5. Это НЕ вероятность того, что истинное значение лежит в конкретном интервале, который мы построили — истинное значение всегда одно и то же, и наш конкретный интервал либо \"поймал\" его, либо нет.\n",
    "\n",
    "Что показывает доверительный интервал?\n",
    "\n",
    "•  Уверенность в оценке: Чем уже доверительный интервал, тем точнее наша оценка, и наоборот, широкий интервал говорит о том, что у нас большая неопределенность.\n",
    "•  Диапазон возможных значений: Интервал показывает, в каком диапазоне значений, вероятно, находится истинное значение (с заданной вероятностью).\n",
    "•  Понимание точности: Доверительный интервал позволяет нам понять, насколько точно мы измерили что-то.\n",
    "\n",
    "Важные моменты:\n",
    "\n",
    "•  Доверительный уровень (например, 95%): Это не вероятность того, что истинное значение лежит в нашем интервале. Это означает, что если бы мы повторили наше исследование много раз, 95% из построенных интервалов содержали бы истинное значение.\n",
    "•  Доверительный интервал не предсказывает конкретное значение, а предсказывает диапазон значений, в котором, вероятно, находится истинное значение.\n",
    "•  Ширина интервала зависит от размера выборки, вариабельности данных и выбранного уровня доверия.\n",
    "•  Вы не знаете, поймал ли конкретно ваш интервал истинное значение — у вас есть только вероятность того, что он находится внутри интервала.\n",
    "\n",
    "В заключение:\n",
    "\n",
    "Доверительный интервал — это инструмент, который позволяет нам оценить не только среднее значение, но и уровень неопределенности этой оценки. Он дает нам \"диапазон уверенности\" вокруг нашей оценки, учитывая, что мы работаем с выборками и что наши измерения всегда имеют некоторую погрешность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265b29c-6c42-48dd-91e6-8da3844f113f",
   "metadata": {},
   "source": [
    "1. Доверительные интервалы для выборок с нормальным распределением\n",
    "\n",
    "Для выборок, которые следуют (или предположительно следуют) нормальному распределению, существует несколько способов расчета ДИ:\n",
    "\n",
    "•  Z-интервал (известно стандартное отклонение популяции): Этот метод используется, когда нам известно стандартное отклонение всей популяции (σ). На практике это бывает редко.\n",
    "•  t-интервал (стандартное отклонение популяции неизвестно): Это наиболее распространенный метод, когда мы имеем только выборочное стандартное отклонение (s). t-распределение учитывает дополнительную неопределенность, связанную с оценкой стандартного отклонения.\n",
    "\n",
    "2. Доверительные интервалы для скошенных выборок (не нормальное распределение)\n",
    "\n",
    "Когда выборки не соответствуют нормальному распределению (и могут быть скошены влево или вправо), стандартные методы на основе t-распределения могут быть неточными. В этом случае применяют другие подходы:\n",
    "\n",
    "•  Бутстрап (Bootstrap): Метод пересэмплирования, не зависящий от распределения данных. Позволяет получить ДИ, даже если исходное распределение ненормально.\n",
    "•  Процентные квантили: Расчет ДИ на основе квантилей (процентилей) распределения, полученного бутстрапом или эмпирически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bba60-6984-4825-b264-9e7d8810f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def z_confidence_interval(data, confidence=0.95, population_std=None):\n",
    "    \"\"\"Вычисляет Z-интервал для выборки с известным стандартным отклонением.\"\"\"\n",
    "\n",
    "    if population_std is None:\n",
    "        raise ValueError(\"Стандартное отклонение популяции должно быть задано.\")\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    z_score = stats.norm.ppf((1 + confidence) / 2)\n",
    "    margin_of_error = z_score * (population_std / np.sqrt(len(data)))\n",
    "    return mean - margin_of_error, mean + margin_of_error\n",
    "\n",
    "\n",
    "def t_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"Вычисляет t-интервал для выборки.\"\"\"\n",
    "    mean = np.mean(data)\n",
    "    degrees_of_freedom = len(data) - 1\n",
    "    t_score = stats.t.ppf((1 + confidence) / 2, degrees_of_freedom)\n",
    "    sample_std = np.std(data, ddof=1) # Выборочное стандартное отклонение (ddof=1)\n",
    "    margin_of_error = t_score * (sample_std / np.sqrt(len(data)))\n",
    "    return mean - margin_of_error, mean + margin_of_error\n",
    "\n",
    "\n",
    "def bootstrap_confidence_interval(data, confidence=0.95, n_iterations=1000):\n",
    "    \"\"\"Вычисляет доверительный интервал с помощью бутстрапа.\"\"\"\n",
    "    \n",
    "    n = len(data)\n",
    "    bootstrap_means = []\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "      bootstrap_sample = np.random.choice(data, size=n, replace=True)\n",
    "      bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "      \n",
    "    lower_percentile = (1 - confidence) / 2\n",
    "    upper_percentile = 1 - lower_percentile\n",
    "    \n",
    "    lower_bound = np.percentile(bootstrap_means, lower_percentile * 100)\n",
    "    upper_bound = np.percentile(bootstrap_means, upper_percentile * 100)\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Пример использования\n",
    "    # Нормально распределенные данные\n",
    "    normal_data = np.random.normal(loc=50, scale=10, size=100)\n",
    "    \n",
    "    # Скошенные вправо данные\n",
    "    skewed_right_data = np.random.exponential(scale=10, size=100)\n",
    "    \n",
    "    # Скошенные влево данные\n",
    "    skewed_left_data = 100 - np.random.exponential(scale=10, size=100)\n",
    "    \n",
    "    confidence_level = 0.95\n",
    "    \n",
    "    # 1. Расчет доверительного интервала\n",
    "    print(\"\\nНормальное распределение:\")\n",
    "    print(f\"Mean: {np.mean(normal_data):.2f}\")\n",
    "    print(f\"Z-interval: {z_confidence_interval(normal_data, confidence_level, population_std=10)}\")\n",
    "    print(f\"t-interval: {t_confidence_interval(normal_data, confidence_level)}\")\n",
    "    print(f\"Bootstrap CI: {bootstrap_confidence_interval(normal_data, confidence_level)}\")\n",
    "    \n",
    "    print(\"\\nСкошенное вправо распределение:\")\n",
    "    print(f\"Mean: {np.mean(skewed_right_data):.2f}\")\n",
    "    print(f\"t-interval: {t_confidence_interval(skewed_right_data, confidence_level)}\")\n",
    "    print(f\"Bootstrap CI: {bootstrap_confidence_interval(skewed_right_data, confidence_level)}\")\n",
    "\n",
    "    print(\"\\nСкошенное влево распределение:\")\n",
    "    print(f\"Mean: {np.mean(skewed_left_data):.2f}\")\n",
    "    print(f\"t-interval: {t_confidence_interval(skewed_left_data, confidence_level)}\")\n",
    "    print(f\"Bootstrap CI: {bootstrap_confidence_interval(skewed_left_data, confidence_level)}\")\n",
    "\n",
    "    # 2. Визуализация данных и доверительных интервалов\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].hist(normal_data, bins=20, alpha=0.6, label=\"Data\")\n",
    "    axes[0].axvline(np.mean(normal_data), color='r', linestyle='dashed', linewidth=1, label='Mean')\n",
    "    lower_normal, upper_normal = t_confidence_interval(normal_data, confidence_level)\n",
    "    axes[0].axvline(lower_normal, color='g', linestyle='dotted', linewidth=1, label='CI')\n",
    "    axes[0].axvline(upper_normal, color='g', linestyle='dotted', linewidth=1)\n",
    "    axes[0].set_title(\"Normal Distribution\")\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].hist(skewed_right_data, bins=20, alpha=0.6, label=\"Data\")\n",
    "    axes[1].axvline(np.mean(skewed_right_data), color='r', linestyle='dashed', linewidth=1, label='Mean')\n",
    "    lower_skewed_right, upper_skewed_right = bootstrap_confidence_interval(skewed_right_data, confidence_level)\n",
    "    axes[1].axvline(lower_skewed_right, color='g', linestyle='dotted', linewidth=1, label='CI')\n",
    "    axes[1].axvline(upper_skewed_right, color='g', linestyle='dotted', linewidth=1)\n",
    "    axes[1].set_title(\"Skewed Right Distribution\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    axes[2].hist(skewed_left_data, bins=20, alpha=0.6, label=\"Data\")\n",
    "    axes[2].axvline(np.mean(skewed_left_data), color='r', linestyle='dashed', linewidth=1, label='Mean')\n",
    "    lower_skewed_left, upper_skewed_left = bootstrap_confidence_interval(skewed_left_data, confidence_level)\n",
    "    axes[2].axvline(lower_skewed_left, color='g', linestyle='dotted', linewidth=1, label='CI')\n",
    "    axes[2].axvline(upper_skewed_left, color='g', linestyle='dotted', linewidth=1)\n",
    "    axes[2].set_title(\"Skewed Left Distribution\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca4826-61ae-45b7-9a20-c59764b21e46",
   "metadata": {},
   "source": [
    "Ключевые моменты:\n",
    "\n",
    "•  Z-интервал vs t-интервал: t-интервал используется чаще, так как обычно стандартное отклонение популяции неизвестно.\n",
    "\n",
    "•  Бутстрап: Подходит для любых распределений, особенно когда распределение далеко от нормального.\n",
    "\n",
    "•  Число итераций бутстрапа (n_iterations): Большее количество итераций даст более точный ДИ, но также потребует больше времени.\n",
    "\n",
    "Когда какой метод использовать:\n",
    "\n",
    "•  Нормальные выборки (или близкие к нормальным): t-интервал.\n",
    "\n",
    "•  Скошенные выборки: Бутстрап (можно с вычислением квантилей).\n",
    "\n",
    "•  Известное стандартное отклонение популяции (редко): Z-интервал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe172e-99a6-4fea-9164-bd5698d0f6f7",
   "metadata": {},
   "source": [
    "Понял, вам нужно создать интервалы для цен за 1 кв.м., которые будут более широкими, чем обычные доверительные интервалы, и учитывать неучтенные факторы ценообразования. Вы хотите, чтобы эти интервалы были в пределах ±20% от среднего значения цены в каждой страте.\n",
    "\n",
    "Это разумный подход, поскольку он позволяет учесть не только статистическую дисперсию данных, но и вариативность, возникающую из-за других факторов, которые вы не можете явно моделировать (таких как местоположение, класс жилья и т.д.).\n",
    "\n",
    "Вот как можно правильно построить такие интервалы:\n",
    "\n",
    "1. Расчет среднего значения:\n",
    "\n",
    "•  Сначала нужно вычислить среднее значение цены за 1 кв.м. для каждой комбинации страт (например, \"площадь от 40 до 60 кв.м.\", \"без отделки\", \"1950-1999\").\n",
    "\n",
    "2. Расчет интервала ±20%:\n",
    "\n",
    "•  Для каждого среднего значения вычисляем верхнюю и нижнюю границы интервала:\n",
    "  •  Нижняя граница = среднее значение × (1 - 0.20)\n",
    "  •  Верхняя граница = среднее значение × (1 + 0.20)\n",
    "\n",
    "3. Опционально: \"Сглаживание\" интервалов\n",
    "\n",
    "•  В некоторых случаях вы можете захотеть сгладить эти интервалы, чтобы они не были слишком резкими или шумными. Это можно сделать, например, взяв скользящее среднее, но тут надо смотреть что подойдет лучше именно под ваши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4c6cd-78a4-4f71-a36f-a18b866d5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_price_intervals(df, area_bins, finish_types, year_bins, lower_bound=0.8, upper_bound=1.2):\n",
    "    \"\"\"\n",
    "    Вычисляет интервалы цен с учетом стратификации и погрешности в %\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame с колонками 'area', 'finish_type', 'year', 'price_per_sqm'\n",
    "        area_bins: список с границами бинов для площади\n",
    "        finish_types: список возможных типов отделки\n",
    "        year_bins: список с границами бинов для годов постройки\n",
    "        lower_bound: нижний предел от среднего (например, 0.8 для -20%)\n",
    "        upper_bound: верхний предел от среднего (например, 1.2 для +20%)\n",
    "    Returns:\n",
    "        pandas DataFrame с колонками 'area_bin', 'finish_type', 'year_bin', 'avg_price', 'lower_bound', 'upper_bound'\n",
    "    \"\"\"\n",
    "\n",
    "    df['area_bin'] = pd.cut(df['area'], bins=area_bins, labels=False, include_lowest=True)\n",
    "    df['year_bin'] = pd.cut(df['year'], bins=year_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    grouped_data = df.groupby(['area_bin', 'finish_type', 'year_bin'])['price_per_sqm'].agg(['mean']).reset_index()\n",
    "    grouped_data['lower_bound'] = grouped_data['mean'] * lower_bound\n",
    "    grouped_data['upper_bound'] = grouped_data['mean'] * upper_bound\n",
    "\n",
    "    return grouped_data.rename(columns={'mean': 'avg_price'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Пример данных\n",
    "    data = {\n",
    "        'area': [45, 55, 70, 80, 40, 50, 65, 75, 42, 52, 72, 82, 48, 58, 68, 78],\n",
    "        'finish_type': ['с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки',\n",
    "                        'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки'],\n",
    "        'year': [1940, 1960, 2010, 2020, 1930, 1970, 2005, 2015, 1945, 1975, 2008, 2018, 1948, 1980, 2003, 2019],\n",
    "        'price_per_sqm': [150000, 120000, 280000, 300000, 130000, 110000, 250000, 290000, 140000, 100000, 260000, 270000,\n",
    "                           160000, 115000, 270000, 280000]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    area_bins = [0, 50, 70, 100] # Разбивка по площади\n",
    "    finish_types = ['с отделкой', 'без отделки']\n",
    "    year_bins = [0, 1949, 1999, 2100] # Разбивка по годам\n",
    "\n",
    "    result_df = calculate_price_intervals(df, area_bins, finish_types, year_bins)\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c7ae3-fefa-4a0b-b6fc-b87e32b96f68",
   "metadata": {},
   "source": [
    "Ключевые моменты:\n",
    "\n",
    "•   Нижний и верхний предел: Вы можете изменять значения lower_bound и upper_bound для настройки ширины интервала.\n",
    "\n",
    "•   Стратификация: Чем больше уровней стратификации, тем более детализированные будут интервалы.\n",
    "\n",
    "•   \"Сглаживание\": Если необходимо, вы можете добавить этап \"сглаживания\" после расчета интервалов. Это может быть, например, скользящее среднее или другие методы, которые учитывают соседние страты.\n",
    "\n",
    "Интерпретация:\n",
    "\n",
    "Теперь у вас есть интервалы цен, которые учитывают как статистическую вариабельность, так и неопределенность, вызванную неучтенными факторами. Вы можете использовать эти интервалы для анализа и сравнения цен в разных стратах, имея более широкое представление о диапазоне цен, в котором может находиться стоимость 1 кв. м."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38163f57-7fa2-46b9-9e57-442758312d58",
   "metadata": {},
   "source": [
    "Проблема с простым ±20%:\n",
    "\n",
    "•  Произвольность: Выбор 20% ничем не обоснован статистически и не опирается на распределение данных.\n",
    "•  Симметричность: Интервал ±20% симметричен относительно среднего, что не подходит для скошенных распределений. Скошенные распределения не симметричны относительно среднего.\n",
    "•  Игнорирование разброса данных: ±20% не учитывает, насколько сильно разбросаны цены внутри страты.\n",
    "•  Надежность: Нет гарантии, что этот интервал будет покрывать \"разумный\" диапазон цен в большинстве случаев.\n",
    "\n",
    "Более обоснованные подходы (с учетом скошенности):\n",
    "\n",
    "1. Использование квантилей (процентилей):\n",
    "\n",
    "  •  Идея: Вместо фиксированного процента, используем квантили (процентили) распределения. Например, можно взять 10-й и 90-й процентили, или 5-й и 95-й.\n",
    "  •  Преимущества:\n",
    "    *  Учитывает скошенность распределения (интервал будет не симметричен).\n",
    "    *  Основан на фактическом распределении данных.\n",
    "  •  Недостатки:\n",
    "    *  Нужно определить, какие процентили использовать (например, 5-й и 95-й).\n",
    "\n",
    "2. Бутстрап для квантильных интервалов:\n",
    "\n",
    "  •  Идея: Используем бутстрап, чтобы получить распределение квантилей.\n",
    "  •  Преимущества:\n",
    "    *  Учитывает скошенность и форму распределения.\n",
    "    *  Даёт оценку неопределенности квантилей.\n",
    "    *  Не требует предположений о нормальности распределения.\n",
    "  •  Недостатки:\n",
    "    *  Требует вычислительных ресурсов.\n",
    "    *  Нужно определить количество бутстрап-итераций.\n",
    "\n",
    "3. Интервалы на основе логарифмированных данных (если скошенность очень сильная):\n",
    "\n",
    "  •  Идея: Логарифмируем данные, делая их распределение более симметричным. Вычисляем интервал на логарифмированных данных, а затем экспоненцируем обратно, чтобы получить интервал для исходных данных.\n",
    "  •  Преимущества:\n",
    "    *  Может помочь при сильной скошенности.\n",
    "  •  Недостатки:\n",
    "    *  Интервал получится на основе логарифмированных данных, а не самих цен.\n",
    "    *  Нужно аккуратно интерпретировать результаты.\n",
    "    *  Логарифмирование не всегда подходит для всех данных.\n",
    "\n",
    "4. Использование гамма-распределения (если есть основания):\n",
    "\n",
    "  •  Идея: Если распределение цен за 1 кв.м. хорошо аппроксимируется гамма-распределением, можно использовать параметры гамма-распределения для расчета интервалов.\n",
    "  •  Преимущества:\n",
    "    *  Учитывает скошенность, свойственную гамма-распределению.\n",
    "  •  Недостатки:\n",
    "    *  Требует проверки соответствия данных гамма-распределению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76c7e4-5d43-4402-bffa-ea1ba2be430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "import math\n",
    "\n",
    "def calculate_quantile_intervals(df, area_bins, finish_types, year_bins, lower_quantile=0.05, upper_quantile=0.95):\n",
    "    \"\"\"\n",
    "    Вычисляет интервалы цен на основе квантилей.\n",
    "\n",
    "    Args:\n",
    "      df: pandas DataFrame с колонками 'area', 'finish_type', 'year', 'price_per_sqm'\n",
    "      area_bins: список с границами бинов для площади\n",
    "      finish_types: список возможных типов отделки\n",
    "      year_bins: список с границами бинов для годов постройки\n",
    "      lower_quantile: нижний квантиль\n",
    "      upper_quantile: верхний квантиль\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame с колонками 'area_bin', 'finish_type', 'year_bin', 'avg_price', 'lower_bound', 'upper_bound'\n",
    "    \"\"\"\n",
    "    df['area_bin'] = pd.cut(df['area'], bins=area_bins, labels=False, include_lowest=True)\n",
    "    df['year_bin'] = pd.cut(df['year'], bins=year_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    def calculate_quantiles(group):\n",
    "        avg_price = group['price_per_sqm'].mean()\n",
    "        lower_bound = group['price_per_sqm'].quantile(lower_quantile)\n",
    "        upper_bound = group['price_per_sqm'].quantile(upper_quantile)\n",
    "        return pd.Series({'avg_price': avg_price, 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "    grouped_data = df.groupby(['area_bin', 'finish_type', 'year_bin']).apply(calculate_quantiles).reset_index()\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "def bootstrap_quantile_intervals(df, area_bins, finish_types, year_bins, lower_quantile=0.05, upper_quantile=0.95, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    Вычисляет интервалы цен с помощью бутстрапа для квантилей.\n",
    "    Args:\n",
    "      df: pandas DataFrame с колонками 'area', 'finish_type', 'year', 'price_per_sqm'\n",
    "      area_bins: список с границами бинов для площади\n",
    "      finish_types: список возможных типов отделки\n",
    "      year_bins: список с границами бинов для годов постройки\n",
    "      lower_quantile: нижний квантиль\n",
    "      upper_quantile: верхний квантиль\n",
    "       n_iterations: количество итераций\n",
    "    Returns:\n",
    "        pandas DataFrame с колонками 'area_bin', 'finish_type', 'year_bin', 'avg_price', 'lower_bound', 'upper_bound'\n",
    "    \"\"\"\n",
    "    df['area_bin'] = pd.cut(df['area'], bins=area_bins, labels=False, include_lowest=True)\n",
    "    df['year_bin'] = pd.cut(df['year'], bins=year_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    def calculate_bootstrap_quantiles(group):\n",
    "        avg_price = group['price_per_sqm'].mean()\n",
    "        bootstrap_quantiles = []\n",
    "\n",
    "        for _ in range(n_iterations):\n",
    "            bootstrap_sample = group['price_per_sqm'].sample(n=len(group), replace=True)\n",
    "            bootstrap_quantiles.append(bootstrap_sample.quantile(lower_quantile))\n",
    "\n",
    "        lower_bound = np.percentile(bootstrap_quantiles, 50)\n",
    "        bootstrap_quantiles = []\n",
    "\n",
    "        for _ in range(n_iterations):\n",
    "            bootstrap_sample = group['price_per_sqm'].sample(n=len(group), replace=True)\n",
    "            bootstrap_quantiles.append(bootstrap_sample.quantile(upper_quantile))\n",
    "\n",
    "        upper_bound = np.percentile(bootstrap_quantiles, 50)\n",
    "        return pd.Series({'avg_price': avg_price, 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "    grouped_data = df.groupby(['area_bin', 'finish_type', 'year_bin']).apply(calculate_bootstrap_quantiles).reset_index()\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "def log_transformed_intervals(df, area_bins, finish_types, year_bins, lower_percent=0.05, upper_percent=0.95):\n",
    "      \"\"\"\n",
    "      Вычисляет интервалы цен на логарифмированных данных.\n",
    "      Args:\n",
    "        df: pandas DataFrame с колонками 'area', 'finish_type', 'year', 'price_per_sqm'\n",
    "        area_bins: список с границами бинов для площади\n",
    "        finish_types: список возможных типов отделки\n",
    "        year_bins: список с границами бинов для годов постройки\n",
    "         lower_percent: нижний квантиль\n",
    "        upper_percent: верхний квантиль\n",
    "\n",
    "      Returns:\n",
    "          pandas DataFrame с колонками 'area_bin', 'finish_type', 'year_bin', 'avg_price', 'lower_bound', 'upper_bound'\n",
    "      \"\"\"\n",
    "      df['area_bin'] = pd.cut(df['area'], bins=area_bins, labels=False, include_lowest=True)\n",
    "      df['year_bin'] = pd.cut(df['year'], bins=year_bins, labels=False, include_lowest=True)\n",
    "\n",
    "      def calculate_log_intervals(group):\n",
    "        log_prices = np.log1p(group['price_per_sqm']) # используем log1p для избежания ошибки в случае 0\n",
    "        avg_price = group['price_per_sqm'].mean() # Используем среднее исходных данных\n",
    "        lower_bound = np.exp(log_prices.quantile(lower_percent))\n",
    "        upper_bound = np.exp(log_prices.quantile(upper_percent))\n",
    "        return pd.Series({'avg_price': avg_price, 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "      grouped_data = df.groupby(['area_bin', 'finish_type', 'year_bin']).apply(calculate_log_intervals).reset_index()\n",
    "      return grouped_data\n",
    "\n",
    "def gamma_fit_intervals(df, area_bins, finish_types, year_bins, lower_percent=0.05, upper_percent=0.95):\n",
    "    \"\"\"\n",
    "    Вычисляет интервалы цен на основе гамма-распределения.\n",
    "     Args:\n",
    "        df: pandas DataFrame с колонками 'area', 'finish_type', 'year', 'price_per_sqm'\n",
    "        area_bins: список с границами бинов для площади\n",
    "        finish_types: список возможных типов отделки\n",
    "        year_bins: список с границами бинов для годов постройки\n",
    "         lower_percent: нижний квантиль\n",
    "        upper_percent: верхний квантиль\n",
    "\n",
    "      Returns:\n",
    "          pandas DataFrame с колонками 'area_bin', 'finish_type', 'year_bin', 'avg_price', 'lower_bound', 'upper_bound'\n",
    "    \"\"\"\n",
    "    df['area_bin'] = pd.cut(df['area'], bins=area_bins, labels=False, include_lowest=True)\n",
    "    df['year_bin'] = pd.cut(df['year'], bins=year_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    def calculate_gamma_intervals(group):\n",
    "          prices = group['price_per_sqm']\n",
    "          avg_price = prices.mean()\n",
    "          alpha, loc, beta = gamma.fit(prices, floc=0)\n",
    "\n",
    "          if math.isnan(alpha):\n",
    "            lower_bound = 0\n",
    "            upper_bound = 0\n",
    "          else:\n",
    "            lower_bound = gamma.ppf(lower_percent, a=alpha, loc=loc, scale=beta)\n",
    "            upper_bound = gamma.ppf(upper_percent, a=alpha, loc=loc, scale=beta)\n",
    "          return pd.Series({'avg_price': avg_price, 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "\n",
    "    grouped_data = df.groupby(['area_bin', 'finish_type', 'year_bin']).apply(calculate_gamma_intervals).reset_index()\n",
    "    return grouped_data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Пример данных\n",
    "    data = {\n",
    "        'area': [45, 55, 70, 80, 40, 50, 65, 75, 42, 52, 72, 82, 48, 58, 68, 78],\n",
    "        'finish_type': ['с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки',\n",
    "                        'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки', 'с отделкой', 'без отделки'],\n",
    "        'year': [1940, 1960, 2010, 2020, 1930, 1970, 2005, 2015, 1945, 1975, 2008, 2018, 1948, 1980, 2003, 2019],\n",
    "        'price_per_sqm': [150000, 120000, 280000, 300000, 130000, 110000, 250000, 290000, 140000, 100000, 260000, 270000,\n",
    "                           160000, 115000, 270000, 280000]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    area_bins = [0, 50, 70, 100]\n",
    "    finish_types = ['с отделкой', 'без отделки']\n",
    "    year_bins = [0, 1949, 1999, 2100]\n",
    "    lower_quantile = 0.05\n",
    "    upper_quantile = 0.95\n",
    "\n",
    "    # 1. Расчет квантильных интервалов\n",
    "    result_quantiles = calculate_quantile_intervals(df, area_bins, finish_types, year_bins, lower_quantile, upper_quantile)\n",
    "    print(\"\\nИнтервалы, расчитанные по квантилям:\\n\", result_quantiles)\n",
    "\n",
    "    # 2. Расчет бутстрап-интервалов\n",
    "    result_bootstrap = bootstrap_quantile_intervals(df, area_bins, finish_types, year_bins, lower_quantile, upper_quantile, n_iterations = 1000)\n",
    "    print(\"\\nИнтервалы, расчитанные при помощи бутстрапа:\\n\", result_bootstrap)\n",
    "\n",
    "    # 3. Интервалы на логарифмированных данных\n",
    "    result_log = log_transformed_intervals(df, area_bins, finish_types, year_bins, lower_percent=lower_quantile, upper_percent=upper_quantile)\n",
    "    print(\"\\nИнтервалы на логарифмированных данных:\\n\", result_log)\n",
    "\n",
    "    # 4. Расчет гамма-интервалов\n",
    "    result_gamma = gamma_fit_intervals(df, area_bins, finish_types, year_bins, lower_percent=lower_quantile, upper_percent=upper_quantile)\n",
    "    print(\"\\nИнтервалы, расчитанные при помощи гамма-распределения:\\n\", result_gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e001f1-8f54-4873-8dfe-cf2d3ca388e7",
   "metadata": {},
   "source": [
    "Выбор метода:\n",
    "  \n",
    "  •  Квантили (процентили): Хороший баланс между простотой и точностью, подходит для большинства случаев скошенного распределения.\n",
    "  \n",
    "  •  Бутстрап для квантильных интервалов: Если хотите более надежную оценку с учетом неопределенности, особенно при небольших выборках.\n",
    "  \n",
    "  •  Логарифмированные данные: Полезно при очень сильной скошенности, но нужно аккуратно интерпретировать результаты.\n",
    "  \n",
    "  •  Гамма-распределение: Применяйте этот метод, если есть основания полагать, что ваше распределение цен за 1 кв.м. можно хорошо аппроксимировать гамма-распределением.\n",
    "\n",
    "•  Выбор квантилей: Подбирайте значения lower_quantile и upper_quantile так, чтобы они покрывали \"разумный\" диапазон цен, с учетом того, что обычно цены могут колебаться. 5% и 95% - это хороший отправной пункт, но в некоторых ситуациях они могут быть слишком широкими или узкими.\n",
    "\n",
    "• Проверка соответствия: Если вы используете гамма распределение, проверьте данные на его соответствие, например, с помощью визуализаций.\n",
    "\n",
    "•  Визуализация: Обязательно постройте гистограммы и добавьте на них полученные интервалы, чтобы визуально оценить их адекватность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487e885-e725-4d5a-9ea2-873b2ccd27ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
