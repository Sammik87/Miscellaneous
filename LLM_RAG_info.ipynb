{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc8ae9b-99ff-44bd-a5c3-3ab5684f5e92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff4ef0-8797-49ab-9078-692c10b96b3e",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30949b8-d151-469c-be70-ef86c12005c1",
   "metadata": {},
   "source": [
    "Использование LLM для задач, связанных с моделированием цен на недвижимость и поиском информации в тексте объявлений, безусловно, перспективно, но требует взвешенного подхода. Давайте разберем плюсы и минусы, а также возможные варианты применения.\n",
    "\n",
    "Плюсы использования LLM:\n",
    "\n",
    "• Более точный и гибкий поиск: LLM могут понимать контекст и семантику текста гораздо лучше, чем простой поиск по ключевым словам. Например, фраза \"с видом на море\" будет распознана даже если в объявлении написано \"панорамный вид на океан\". Они способны выявлять косвенные признаки, например, \"рядом с парком\" может указывать на благоприятную экологическую обстановку, что влияет на стоимость.\n",
    "• Автоматическое создание новых факторов: LLM могут автоматически извлекать информацию о характеристиках недвижимости, которые вы могли бы пропустить при ручном анализе. Например, они могут определить наличие парковки, тип отопления, наличие лифта, даже по косвенным признакам в описании. Это значительно расширяет набор факторов для вашей модели.\n",
    "• Обработка неструктурированных данных: Объявления о недвижимости часто содержат неструктурированный текст, таблицы, изображения. LLM могут помочь структурировать эту информацию и извлекать из неё полезные данные.\n",
    "• Многоязычная поддержка: Если вы работаете с объявлениями на разных языках, LLM обеспечат единый подход к обработке данных.\n",
    "• Улучшение качества данных: LLM могут помочь очистить данные, выявляя и корректируя неточности и опечатки в текстах объявлений.\n",
    "\n",
    "\n",
    "Минусы использования LLM:\n",
    "\n",
    "• Стоимость: Использование LLM может быть дорогостоящим, особенно при обработке больших объемов данных. Вам нужно будет оценить затраты на вычисления и API-вызовы.\n",
    "• Требуется качественная подготовка данных: Для эффективной работы LLM необходимы хорошо подготовленные и очищенные данные. Некачественные данные приведут к неточным результатам.\n",
    "• Сложность интеграции: Интеграция LLM в существующую систему может потребовать значительных усилий по разработке и тестированию.\n",
    "• Объяснение результатов: LLM могут давать неожиданные результаты, которые трудно интерпретировать. Важно понимать, как модель приходит к своим выводам, чтобы избежать ошибок.\n",
    "• Предвзятость: LLM обучаются на больших данных, которые могут содержать предвзятость. Эта предвзятость может отразиться на результатах работы модели.\n",
    "\n",
    "\n",
    "Как использовать LLM в моделировании стоимости недвижимости:\n",
    "\n",
    "1. Извлечение признаков: Используйте LLM для автоматического извлечения признаков из текстов объявлений (площадь, количество комнат, наличие балкона/террасы, состояние ремонта, описание района и т.д.).\n",
    "2. Классификация: Классифицируйте недвижимость по типам (квартира, дом, таунхаус), состоянию (новостройка, вторичное жилье), классу (эконом, комфорт, премиум).\n",
    "3. Определение местоположения: LLM могут помочь уточнить местоположение объекта, используя информацию из текста.\n",
    "4. Анализ настроения: Определите общий тон описания объекта, что может указывать на его привлекательность для потенциальных покупателей.\n",
    "5. Генерация описаний: (Дополнительно) LLM могут помочь генерировать более качественные и полные описания для объявлений.\n",
    "\n",
    "\n",
    "Рекомендации:\n",
    "\n",
    "• Начните с пилотного проекта: Проверьте эффективность LLM на небольшой выборке данных перед развертыванием на весь объем.\n",
    "• Выберите подходящую модель: Выбор модели зависит от ваших задач и ресурсов. Некоторые модели лучше подходят для извлечения информации, другие – для классификации.\n",
    "• Оцените затраты: Учтите стоимость вычислений и API-вызовов при планировании проекта.\n",
    "• Мониторинг и оценка: Регулярно контролируйте качество работы модели и вносите необходимые корректировки.\n",
    "\n",
    "\n",
    "В заключение, использование LLM для анализа текстов объявлений о недвижимости и построения моделей оценки стоимости – это перспективное направление. Однако необходимо тщательно взвесить плюсы и минусы, подобрать подходящую модель и стратегию, и подготовить качественные данные для достижения наилучших результатов. Начнит\n",
    "е с небольшого пилотного проекта, чтобы оценить эффективность и рентабельность использования LLM в вашем конкретном случае."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f6fe2-b88b-49f7-8b0e-1509e9b146f4",
   "metadata": {},
   "source": [
    "BERT, включая ruBERT, хорошо подходит для задач анализа текста, таких как извлечение информации из объявлений о недвижимости. Однако, для прямого поиска \"квартир с террасами\" BERT не является оптимальным инструментом. BERT – это модель для понимания контекста и семантики, а не для поиска по ключевым словам. Для простого поиска ключевого слова \"терраса\" достаточно было бы более простого метода, например, in оператора в Python. BERT же эффективнее проявляет себя, когда дело касается более сложных и неоднозначных формулировок.\n",
    "\n",
    "Поэтому, я покажу пример использования ruBERT для более сложной задачи – определения наличия террасы по более обширному описанию, где простого поиска \"терраса\" может быть недостаточно. Мы будем использовать бинарную классификацию: есть терраса (1) или нет (0).\n",
    "\n",
    "Этот код требует установки необходимых библиотек: transformers, datasets, scikit-learn. Установите их с помощью pip: pip install transformers datasets scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626362f9-adac-46a1-8299-ed735692dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели ruBERT для бинарной классификации (вам нужно найти подходящую модель)\n",
    "model_name = \"cointegrated/rubert-tiny2\" # Замените на имя подходящей модели.  Важно, чтобы модель была обучена для бинарной классификации!\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Пример данных (вам нужно заменить это на ваши реальные данные!)\n",
    "data = [\n",
    "    {\"text\": \"Квартира с прекрасным видом, большая лоджия.\", \"label\": 0},  # 0 - нет террасы\n",
    "    {\"text\": \"Просторный дом с террасой и бассейном.\", \"label\": 1},  # 1 - есть терраса\n",
    "    {\"text\": \"Уютная квартира, балкон выходит на тихий двор.\", \"label\": 0},\n",
    "    {\"text\": \"Продается квартира с собственной террасой.\", \"label\": 1},\n",
    "    {\"text\": \"Современная квартира, панорамные окна, выход на просторную террасу.\", \"label\": 1},\n",
    "    {\"text\": \"Дом с участком и небольшой верандой.\", \"label\": 0}, # Небольшая веранда - не терраса в контексте данной модели.\n",
    "    {\"text\": \"Квартира-студия без балкона и террас.\", \"label\": 0},\n",
    "]\n",
    "\n",
    "# Преобразование данных в Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Токенизация данных\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Разделение данных на тренировочный и тестовый наборы\n",
    "train_testvalid = tokenized_datasets.train_test_split(test_size=0.2, seed=42)\n",
    "train_valid = train_testvalid['train'].train_test_split(test_size=0.25, seed=42)\n",
    "train_dataset = train_valid['train']\n",
    "valid_dataset = train_valid['test']\n",
    "test_dataset = train_testvalid['test']\n",
    "\n",
    "\n",
    "# Обучение модели (вам нужно будет настроить гиперпараметры)\n",
    "model.train() # Важно!\n",
    "\n",
    "# (Здесь должен быть код обучения модели.  Это упрощенный пример,  для реальных данных потребуется более сложная процедура обучения с использованием, \n",
    "# например, Trainer из библиотеки transformers)\n",
    "# ... (Код обучения модели,  включая итерации, оптимизатор, функции потерь и т.д.  Это требует знания PyTorch или TensorFlow.) ...\n",
    "\n",
    "# Предсказание на тестовом наборе\n",
    "predictions = model.predict(test_dataset['input_ids'])\n",
    "\n",
    "\n",
    "# Оценка модели (пример)\n",
    "predictions_labels = predictions.logits.argmax(axis=-1)\n",
    "true_labels = test_dataset['label']\n",
    "accuracy = accuracy_score(true_labels, predictions_labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(true_labels, predictions_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d9699-947e-40bc-9071-96ba0aa8f653",
   "metadata": {},
   "source": [
    "Важно: Этот код – упрощенный пример. Для реального применения вам потребуется:\n",
    "\n",
    "1. Большой и качественный набор данных: Вам нужно собрать значительное количество объявлений о недвижимости, ручно пометив их как \"есть терраса\" (1) или \"нет террасы\" (0). Качество разметки критически важно для точности модели.\n",
    "2. Настройка гиперпараметров: Процесс обучения потребует эксперимента с различными гиперпараметрами (размер батча, скорость обучения, количество эпох) для достижения оптимальной производительности. Это может занять много времени и вычислительных ресурсов.\n",
    "3. Более сложная модель обучения: Вместо простого model.train() вам понадобится реализовать полноценный цикл обучения с использованием Trainer из библиотеки transformers или других инструментов для глубокого обучения.\n",
    "4. Выбор подходящей предобученной модели: cointegrated/rubert-tiny2 - это лишь пример. Вам нужно будет исследовать различные модели ruBERT, чтобы найти наиболее подходящую для вашей задачи. Возможно, потребуется тонкая настройка (fine-tuning) выбранной модели на ваших данных.\n",
    "5. Обработка ошибок: Код должен включать обработку потенциальных ошибок, например, ошибок при загрузке данных или во время обучения модели.\n",
    "\n",
    "\n",
    "Помните, что использование LLM для таких задач – это сложная задача, требующая глубоких знаний в области обработки естественного языка и машинного обучения. Этот код – только отправная точка. Для успешного завершения проекта потребуется значительное время и усилия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593b70c-9d9c-4379-997f-ce964664fd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535ab0a-8e88-492e-ba75-5fe9e4715f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8e78a-5e79-46ef-a801-65d1d3e9e7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4095525-0ec5-4757-9b69-f643e0669ff7",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014e6ef-2214-427c-b70f-a75cb7674c6a",
   "metadata": {},
   "source": [
    "RAG в LLM означает Retrieval-Augmented Generation. Это техника, используемая для улучшения работы больших языковых моделей (LLM), таких как GPT-4, путем предоставления им информации из внешних источников при генерации текста.\n",
    "\n",
    "Проблема, которую RAG решает:\n",
    "\n",
    "LLM обучаются на огромных объемах данных, но:\n",
    "\n",
    "•  Они не знают всего: У них нет знаний о событиях, произошедших после их обучения, или о специфической информации, которая не была включена в их обучающий набор данных.\n",
    "•  Они могут галлюцинировать: Они могут генерировать неточные или вымышленные факты, особенно когда пытаются ответить на вопросы о малоизвестных темах.\n",
    "•  Они ограничены контекстом: Они могут испытывать трудности с ответами на вопросы, требующие информации из длинных документов или нескольких источников.\n",
    "\n",
    "Как работает RAG:\n",
    "\n",
    "RAG состоит из двух основных этапов:\n",
    "\n",
    "1. Retrieval (Извлечение):\n",
    "  •  Когда пользователь задает вопрос, система RAG сначала ищет релевантную информацию из внешних источников знаний. Эти источники могут быть:\n",
    "    *  Базы знаний: Структурированные репозитории информации, такие как Википедия, внутренние базы данных компании.\n",
    "    *  Документы: PDF-файлы, текстовые файлы, веб-страницы.\n",
    "    *  API: Интерфейсы для получения информации из других систем.\n",
    "\n",
    "  •  Для поиска релевантной информации используются различные методы, такие как:\n",
    "    *  Semantic Search (Семантический поиск): Поиск документов, которые семантически похожи на вопрос пользователя, даже если они не содержат тех же ключевых слов. Это обычно достигается с помощью векторных представлений текста (embeddings).\n",
    "    *  Keyword Search (Поиск по ключевым словам): Более традиционный метод поиска, основанный на совпадении ключевых слов.\n",
    "\n",
    "2. Generation (Генерация):\n",
    "  •  После того, как релевантная информация извлечена, она объединяется с исходным вопросом пользователя и передается LLM.\n",
    "  •  LLM использует эту объединенную информацию для генерации ответа. Он использует как свои собственные знания, так и предоставленную контекстную информацию для формирования точного и информативного ответа.\n",
    "\n",
    "Преимущества RAG:\n",
    "\n",
    "•  Улучшенная точность: Предоставляя LLM информацию из внешних источников, RAG помогает снизить риск галлюцинаций и повысить точность ответов.\n",
    "•  Актуальность: RAG позволяет LLM предоставлять информацию о последних событиях и изменениях, даже если они произошли после обучения модели.\n",
    "•  Специфические знания: RAG позволяет LLM отвечать на вопросы о специализированных темах, предоставляя ему доступ к соответствующим базам знаний.\n",
    "•  Улучшенная объяснимость: RAG может предоставлять ссылки на источники информации, которые он использовал для генерации ответа, что повышает доверие к ответам.\n",
    "•  Меньшие затраты на переобучение: Вместо того, чтобы переобучать LLM с новыми данными, можно просто обновить внешние источники знаний и использовать RAG для предоставления этой информации LLM.\n",
    "\n",
    "Примеры использования RAG:\n",
    "\n",
    "•  Чат-боты: RAG может использоваться для создания чат-ботов, которые могут отвечать на вопросы о продуктах компании, политиках и процедурах, используя информацию из внутренних баз знаний.\n",
    "•  Поиск информации: RAG может использоваться для улучшения результатов поиска, предоставляя пользователям более релевантные и информативные ответы.\n",
    "•  Генерация контента: RAG может использоваться для автоматической генерации контента, такого как статьи, отчеты и резюме, используя информацию из различных источников.\n",
    "\n",
    "Технологии, используемые в RAG:\n",
    "\n",
    "•  Vector Databases (Векторные базы данных): Для хранения и поиска векторных представлений текста (embeddings). Примеры: Pinecone, Weaviate, FAISS.\n",
    "•  Embedding Models (Модели эмбеддингов): Для создания векторных представлений текста. Примеры: OpenAI Embeddings, Sentence Transformers.\n",
    "•  LLM (Большие языковые модели): Для генерации текста. Примеры: GPT-3, GPT-4, Llama 2.\n",
    "•  Frameworks (Фреймворки): Для упрощения разработки RAG-систем. Примеры: LangChain, Llama\n",
    "Index.\n",
    "\n",
    "В заключение:\n",
    "\n",
    "RAG - это мощный подход к улучшению работы LLM, который позволяет им получать доступ к актуальной, точной и специфической информации из внешних источников знаний. Он является важным инструментом для создания более надежных и полезных приложений на основе LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddded65-31a2-452b-b0f6-1a34690a9665",
   "metadata": {},
   "source": [
    "Large Language Models (LLM) и Retriever-Reader Architectures (RAG), особенно в контексте русского языка. Давайте разберем ваши вопросы подробнее:\n",
    "\n",
    "**Построение LLM моделей**\n",
    "1. Общие принципы:\n",
    "\n",
    "Данные: Для обучения модели нужны большие объемы текстовых данных. В случае с русским языком можно использовать корпуса текстов из интернета, книг, новостей и других источников.\n",
    "Архитектура: Часто используются архитектуры, такие как Transformer, которые показывают хорошие результаты в задачах NLP.\n",
    "Обучение: Процесс обучения может занять много времени и требует значительных вычислительных ресурсов.\n",
    "2. Примеры моделей:\n",
    "\n",
    "BERT: Модель, основанная на подходе Transformer, которая показала отличные результаты в различных задачах NLP.\n",
    "GPT: Серия моделей, разработанная OpenAI, известных своими способностями генерации текста.\n",
    "\n",
    "**Построение LLM моделей на основе предобученных LLM**\n",
    "1. Fine-tuning:\n",
    "\n",
    "Процесс адаптации предобученной модели под конкретную задачу или домен.\n",
    "Например, можно взять предобученную модель GPT и fine-tune её на корпусе текстов на русском языке для улучшения понимания и генерации текста на этом языке.\n",
    "2. Примеры:\n",
    "\n",
    "T5 (Text-to-Text Transfer Transformer): Модель, которая может быть адаптирована для выполнения различных задач путем формулировки задачи в виде преобразования текста.\n",
    "mT5: Мультиязычная версия T5, которая была обучена на большом количестве языков, включая русский.\n",
    "\n",
    "**Реализация RAG**\n",
    "1. Основные компоненты:\n",
    "\n",
    "Retriever: Компонент, который извлекает наиболее релевантные документы или фрагменты текста из базы знаний.\n",
    "Reader: Компонент, который анализирует извлеченные данные и формирует ответ на вопрос пользователя.\n",
    "2. Примеры реализации:\n",
    "\n",
    "Использование модели BERT для роли retriever и модели T5 для роли reader.\n",
    "Можно также использовать другие модели, такие как DPR (Dense Passage Retrieval) для retriever и T5 для reader.\n",
    "3. Пример на практике:\n",
    "\n",
    "Предположим, у вас есть база знаний на русском языке. Вы можете использовать модель DPR для извлечения релевантных документов и затем модель T5 для генерации ответа на основе этих документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35eea20-f91b-4a09-94a8-97e622224ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "\n",
    "# Инициализация токенизатора\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "\n",
    "# Инициализация retriever\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "\n",
    "# Инициализация модели\n",
    "model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# Формирование запроса\n",
    "input_text = \"Как работает RAG?\"\n",
    "input_ids = tokenizer.prepare_seq2seq_batch([input_text], return_tensors=\"pt\")\n",
    "\n",
    "# Генерация ответа\n",
    "outputs = model.generate(input_ids=input_ids[\"input_ids\"])\n",
    "\n",
    "# Декодирование ответа\n",
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1480506-9ff2-4a89-8695-9df5dbc2497a",
   "metadata": {},
   "source": [
    "Конечно, давайте разберёмся с Retriever-Reader Architecture (RAG) простым языком и рассмотрим, как это можно применить к вашей задаче с базой знаний и гигачатом Сбера.\n",
    "\n",
    "### Что такое RAG?\n",
    "\n",
    "**Retriever-Reader Architecture (RAG)** — это метод, который объединяет два компонента для ответа на вопросы пользователей:\n",
    "\n",
    "1. **Retriever (Известитель):**\n",
    "   - **Задача:** Находит наиболее релевантные документы или фрагменты текста из базы знаний.\n",
    "   - **Пример:** Если пользователь задаёт вопрос \"Как работает RAG?\", retriever найдёт наиболее подходящие разделы или статьи из базы знаний.\n",
    "\n",
    "2. **Reader (Чтец):**\n",
    "   - **Задача:** Анализирует найденные документы и формирует точный и полезный ответ на вопрос пользователя.\n",
    "   - **Пример:** После того, как retriever нашёл релевантные статьи, reader прочитает их и составит ответ, например: \"RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\"\n",
    "\n",
    "### Как это работает?\n",
    "\n",
    "1. **Пользователь задаёт вопрос.**\n",
    "2. **Retriever ищет релевантные документы в базе знаний.**\n",
    "3. **Reader анализирует найденные документы и формирует ответ.**\n",
    "4. **Система отправляет ответ пользователю.**\n",
    "\n",
    "### Как это можно применить к вашей задаче с базой знаний и гигачатом Сбера?\n",
    "\n",
    "1. **Подготовка базы знаний:**\n",
    "   - Убедитесь, что ваша база знаний структурирована и содержит все необходимые данные.\n",
    "   - Документы должны быть чётко сформулированы и легко читаемы.\n",
    "\n",
    "2. **Интеграция с гигачатом Сбера:**\n",
    "   - Гигачат Сбера уже имеет встроенные механизмы для работы с базами знаний, но вам нужно будет настроить его для вашего конкретного случая.\n",
    "   - Обычно требуется интеграция через API или другие интерфейсы, предоставляемые Сбером.\n",
    "\n",
    "3. **Настройка Retriever:**\n",
    "   - Выберите подходящий алгоритм для извлечения релевантных документов. Это могут быть методы на основе векторного представления текста (например, Faiss, Annoy) или более сложные модели, такие как BERT для извлечения признаков.\n",
    "   - Убедитесь, что retriever эффективно находит наиболее релевантные документы.\n",
    "\n",
    "4. **Настройка Reader:**\n",
    "   - Выберите модель для анализа найденных документов и формирования ответов. Это может быть предобученная модель, такая как T5, GPT или другие модели, которые поддерживают русский язык.\n",
    "   - Убедитесь, что reader правильно интерпретирует содержание документов и составляет точные и полезные ответы.\n",
    "\n",
    "### Подводные камни\n",
    "\n",
    "1. **Качество базы знаний:**\n",
    "   - Неполные или неструктурированные данные могут привести к некачественным ответам.\n",
    "   - Необходимо регулярно обновлять и проверять базу знаний.\n",
    "\n",
    "2. **Точность извлечения документов:**\n",
    "   - Неправильный retriever может найти неверные или неактуальные документы.\n",
    "   - Требуется тщательное тестирование и настройка retriever для достижения высокой точности.\n",
    "\n",
    "3. **Качество формирования ответов:**\n",
    "   - Некачественный reader может составлять непонятные или неточные ответы.\n",
    "   - Необходимо тщательно настраивать и тестировать reader.\n",
    "\n",
    "4. **Вычислительные ресурсы:**\n",
    "   - Работа с большими базами знаний и сложными моделями требует значительных вычислительных ресурсов.\n",
    "   - Возможно, потребуется облачное хранилище и вычислительные мощности.\n",
    "\n",
    "5. **Интеграция и масштабируемость:**\n",
    "   - Интеграция с гигачатом Сбера должна быть гладкой и масштабируемой.\n",
    "   - Необходимо учитывать возможности и ограничения системы Сбера.\n",
    "\n",
    "### Пример процесса\n",
    "\n",
    "1. **Пользователь задаёт вопрос:** \"Как работает RAG?\"\n",
    "2. **Retriever находит релевантные документы:** Находит статьи о RAG в базе знаний.\n",
    "3. **Reader анализирует документы и формирует ответ:** Читает статьи и составляет ответ: \"RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\"\n",
    "4. **Гигачат Сбера отправляет ответ пользователю:** Пользователь получает ответ на свой вопрос.\n",
    "\n",
    "### Заключение\n",
    "\n",
    "Использование RAG для интеграции базы знаний с гигачатом Сбера — это мощный подход для автоматизации ответов на вопросы пользователей. Однако требуются тщательная подготовка базы знаний, правильная настройка retriever и reader, а также учёт возможных подводных камней. Следуя этим рекомендациям, вы сможете успешно внедрить систему, которая будет помогать пользователям быстро и точно находить информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef20aea-bc56-420c-8bab-7bad4b551e0b",
   "metadata": {},
   "source": [
    "### Что такое RAG простыми словами?  \n",
    "RAG (Retrieval-Augmented Generation) — это метод, который позволяет языковой модели (LLM) искать нужную информацию в базе знаний перед генерацией ответа. Вместо того чтобы полагаться только на свою \"память\" (то есть на то, что было в её обучающем датасете), модель сначала ищет релевантные документы, а затем использует их для построения более точного ответа.  \n",
    "\n",
    "### Как работает RAG?  \n",
    "1. **Индексирование базы знаний**:  \n",
    "   - Документы разбиваются на куски (чаще всего несколько предложений или абзац).  \n",
    "   - Из каждого куска создаётся embedding (векторное представление).  \n",
    "   - Все embedding'и сохраняются в векторную базу (например, FAISS, ChromaDB).  \n",
    "\n",
    "2. **Обработка запроса пользователя**:  \n",
    "   - Запрос пользователя тоже превращается в embedding.  \n",
    "   - Производится поиск ближайших embedding'ов (наиболее похожих фрагментов текста) в базе.  \n",
    "   - Найденные фрагменты передаются в LLM в качестве контекста для генерации ответа.  \n",
    "\n",
    "3. **Генерация ответа**:  \n",
    "   - LLM получает вопрос + найденные фрагменты.  \n",
    "   - На основе этого генерирует ответ, используя свой предобученный язык.  \n",
    "\n",
    "### Что важно учитывать при загрузке базы знаний в ГигаЧат?  \n",
    "\n",
    "#### 🔹 **1. Качество данных**  \n",
    "- Если база знаний плохо структурирована (например, PDF с картинками или плохо отсканированные документы), данные могут плохо индексироваться.  \n",
    "- Дублирующаяся информация может привести к путанице (LLM может запутаться, какой источник выбрать).  \n",
    "\n",
    "#### 🔹 **2. Длина контекста LLM**  \n",
    "- У любой модели есть ограничение на количество токенов в контексте (например, 4k, 8k или 32k токенов).  \n",
    "- Если куски текста слишком большие, модель может не уместить их все и пропустить важную информацию.  \n",
    "- Если куски текста слишком маленькие, могут теряться связи между фактами.  \n",
    "\n",
    "#### 🔹 **3. Метрики качества поиска**  \n",
    "- Если векторная база плохо настроена, поиск может выдавать нерелевантные фрагменты.  \n",
    "- Важно контролировать, насколько найденные куски текста действительно отвечают на запрос.  \n",
    "\n",
    "#### 🔹 **4. Поддержка русского языка**  \n",
    "- Некоторые embedding-модели работают хуже на русском, чем на английском.  \n",
    "- Стоит проверить, какую модель использует ГигаЧат для поиска (например, ruBERT, Mistral, или что-то другое).  \n",
    "\n",
    "### Подводные камни  \n",
    "1. **\"Галлюцинации\" модели**  \n",
    "   - LLM может выдумывать ответы, если в базе нет точной информации.  \n",
    "   - Нужна проверка, чтобы модель ссылалась только на данные из базы.  \n",
    "\n",
    "2. **Медленный поиск**  \n",
    "   - Если база знаний большая, поиск в векторной БД может тормозить.  \n",
    "   - Оптимизация индексов и правильный подбор embedding-модели могут ускорить работу.  \n",
    "\n",
    "3. **Обновление базы знаний**  \n",
    "   - Если база изменяется часто, векторные представления нужно пересоздавать.  \n",
    "   - Важно предусмотреть механизм обновления индексов.  \n",
    "\n",
    "Если ты планируешь загружать базу знаний в ГигаЧат, то важно выяснить:  \n",
    "- Какой формат данных он принимает?  \n",
    "- Какая векторная БД используется для поиска?  \n",
    "- Как ограничивается длина контекста?  \n",
    "\n",
    "Если нужно, можем разобрать конкретные шаги по загрузке базы в ГигаЧат. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af89e8-ea67-4f2d-bd10-466a8ac5e944",
   "metadata": {},
   "source": [
    "# Агент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f01fa-babe-4d1b-90a8-78d3d6245c30",
   "metadata": {},
   "source": [
    "Отличный вопрос! Сейчас популярно писать **агентов на основе LLM**, особенно в контексте RAG или автоматизации задач. Давай по порядку и простым языком.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Что такое **агент**?\n",
    "\n",
    "**Агент** (LLM Agent) — это надстройка над языковой моделью, которая может:\n",
    "- **принимать решение**, что делать с запросом;\n",
    "- **использовать инструменты (tools)**, если нужно;\n",
    "- **объединять несколько шагов** (многошаговая логика);\n",
    "- **запрашивать внешние данные**, если не хватает контекста;\n",
    "- **генерировать финальный ответ** на основе промежуточных шагов.\n",
    "\n",
    "> Агент = LLM + логика + инструменты + память (по желанию)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Для чего пишут агента?\n",
    "\n",
    "Агент нужен, когда просто LLM **недостаточно**:\n",
    "\n",
    "| Без агента | С агентом |\n",
    "|------------|-----------|\n",
    "| LLM просто отвечает на вопрос | Агент может сначала сходить в базу, получить данные, потом сформировать ответ |\n",
    "| Не может делать сложные цепочки | Может проводить серию действий (например, сделать расчет, вызвать API, сформировать отчет) |\n",
    "| Нет доступа к внешнему миру | Может использовать инструменты, подключённые к интернету, базе знаний, функциям и т. д. |\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠️ Что такое **tools / Retriever**?\n",
    "\n",
    "- **Tool** — это внешний инструмент, которым агент может пользоваться.  \n",
    "  Например:\n",
    "  - `search_docs(query)`: поиск в базе знаний;\n",
    "  - `calculate(expression)`: калькулятор;\n",
    "  - `run_sql(query)`: выполнение SQL-запроса;\n",
    "  - `get_weather(city)`: запрос к API погоды.\n",
    "\n",
    "- **Retriever** — это специальный инструмент, который ищет информацию в базе знаний.  \n",
    "  Обычно работает через векторный поиск (embedding → nearest neighbors).  \n",
    "  В контексте RAG retriever ищет нужные куски текста.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Как работает агент на практике:\n",
    "\n",
    "1. Пользователь: \"Какие условия возврата товара в интернет-магазине?\"\n",
    "2. Агент:\n",
    "   - Понимает, что ему нужно обратиться к базе знаний.\n",
    "   - Вызывает tool `retriever.search(\"возврат товара\")`.\n",
    "   - Получает кусок документа с политикой возврата.\n",
    "   - На основе этого генерирует ответ:  \n",
    "     \"Вы можете вернуть товар в течение 14 дней, если...\"\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Что делает агент:\n",
    "\n",
    "- Делает **разбор запроса**\n",
    "- Решает, **нужно ли вызвать инструмент**\n",
    "- Вызывает нужный tool (retriever, калькулятор, API и т.д.)\n",
    "- Обрабатывает результат\n",
    "- Генерирует финальный ответ\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 Пример базового агента на Python (с псевдо-Retriever):\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Предположим, у нас есть retriever (поиск по базе знаний)\n",
    "retriever_tool = Tool(\n",
    "    name=\"KnowledgeBaseSearch\",\n",
    "    func=lambda q: \"Товары можно вернуть в течение 14 дней\",\n",
    "    description=\"Поиск по базе знаний компании\"\n",
    ")\n",
    "\n",
    "# Используем OpenAI или любую LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Создаём агента\n",
    "agent = initialize_agent(\n",
    "    tools=[retriever_tool],\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Запрос пользователя\n",
    "query = \"Какие условия возврата товара?\"\n",
    "response = agent.run(query)\n",
    "\n",
    "print(\"Ответ агента:\", response)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Если тебе нужно:\n",
    "- 🔹 Создать retriever на своей базе знаний (например, txt, PDF, HTML),\n",
    "- 🔹 Подключить к ГигаЧату или к любой другой модели (например, Сбер’s FRED T5, ruGPT, или Mistral),\n",
    "- 🔹 Настроить агента, который будет использовать tools и retriever,\n",
    "\n",
    "— я помогу собрать этот пайплайн. Только скажи, где ты хочешь запускать это (локально или в облаке) и какие данные есть. Готов собрать с нуля."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a00d37-3f49-4988-9f90-9064e12a7b2e",
   "metadata": {},
   "source": [
    "Отлично! Давай сделаем простой, но **реальный пример агента с retriever** на Python. Он будет:\n",
    "\n",
    "1. Загружать твои документы (например, `.txt`, `.pdf`, `.md`).\n",
    "2. Делать embedding'и (векторные представления).\n",
    "3. Идексировать их через FAISS.\n",
    "4. Использовать LangChain-агента, который обращается к Retriever Tool.\n",
    "5. Генерировать ответ с помощью LLM (можно использовать OpenAI, HuggingFace или СберГигаЧат).\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Что нужно:\n",
    "- Python 3.10+\n",
    "- Установленные библиотеки:\n",
    "```bash\n",
    "pip install langchain faiss-cpu openai sentence-transformers\n",
    "```\n",
    "\n",
    "(или `pypdf` и `unstructured` для чтения pdf/docx, если нужно)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Что можно доработать:\n",
    "- Заменить `OpenAI()` на ГигаЧат или HuggingFace модель (`Sberbank-ai/rugpt3medium_based_on_gpt2`, `Mistral`, `phi2` и т.п.).\n",
    "- Подключить PDF-документы вместо `.txt`.\n",
    "- Хранить FAISS базу на диске (для повторного использования).\n",
    "- Собирать историю диалога (memory).\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 Хочешь:\n",
    "- Чтобы я дал тебе точный код с поддержкой PDF?\n",
    "- Подключить ГигаЧат вместо OpenAI?\n",
    "- Написать это как FastAPI-сервис?\n",
    "\n",
    "Скажи, в каком формате тебе это нужно, и я адаптирую!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1490589-651a-4fb3-b135-c9a8cd606960",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 📦 Пример: агент с retriever на `.txt`-файлах\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "# 1. Загружаем документы\n",
    "loader = TextLoader(\"knowledge_base.txt\")  # твой файл\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Разбиваем на куски\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Создаём embedding модель (русская совместимая)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "# 4. Создаём FAISS индекс\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 5. Делаем Retrieval QA chain\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),  # можешь заменить на LLM от HuggingFace\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# 6. Создаём Tool для агента\n",
    "retriever_tool = Tool(\n",
    "    name=\"KnowledgeBaseSearch\",\n",
    "    func=retrieval_chain.run,\n",
    "    description=\"Полезно для поиска информации в базе знаний компании\"\n",
    ")\n",
    "\n",
    "# 7. Создаём агента\n",
    "agent = initialize_agent(\n",
    "    tools=[retriever_tool],\n",
    "    llm=OpenAI(),  # здесь можно заменить на любую LLM\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 8. Запрос пользователя\n",
    "query = \"Как можно вернуть товар, если он не подошёл?\"\n",
    "response = agent.run(query)\n",
    "\n",
    "print(\"Ответ агента:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d284f5-6727-4114-8d4c-1ac45afd973f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b36f16b-8a8c-4af9-8d65-18f4dd5f2358",
   "metadata": {},
   "source": [
    "Конечно! Давайте подробно рассмотрим, что такое **агент**, какие функции он выполняет, и что такое **tools** и **Retriever**. Затем я покажу, как можно написать простого агента на Python.\n",
    "\n",
    "### Что такое Агент?\n",
    "\n",
    "**Агент** (Agent) в контексте искусственного интеллекта — это программа или система, способная автономно выполнять задачи, принимать решения и взаимодействовать с окружающей средой. Агенты часто используются в различных приложениях, таких как чат-боты, виртуальные ассистенты, системы управления задачами и т.д.\n",
    "\n",
    "#### Для чего пишут агентов?\n",
    "\n",
    "1. **Автоматизация задач:** Автоматическое выполнение повторяющихся операций.\n",
    "2. **Взаимодействие с пользователями:** Ответ на вопросы, предоставление информации, помощь в решении проблем.\n",
    "3. **Интеграция с различными сервисами:** Взаимодействие с базами данных, API внешних сервисов, другими системами.\n",
    "4. **Принятие решений:** Анализ данных и принятие оптимальных решений на основе полученной информации.\n",
    "\n",
    "#### Функции агента\n",
    "\n",
    "1. **Получение информации:** Сбор данных из различных источников.\n",
    "2. **Обработка данных:** Анализ и обработка полученной информации.\n",
    "3. **Принятие решений:** Определение оптимальных действий на основе анализа.\n",
    "4. **Выполнение действий:** Автоматическое выполнение задач на основе принятых решений.\n",
    "5. **Взаимодействие с пользователем:** Ответ на вопросы, предоставление информации, инструкции.\n",
    "\n",
    "### Что такое Tools и Retriever?\n",
    "\n",
    "#### Tools (Инструменты)\n",
    "\n",
    "**Tools** — это набор функций или операций, которые агент может использовать для выполнения различных задач. Эти инструменты могут включать в себя:\n",
    "\n",
    "- **API внешних сервисов:** Например, API для доступа к базам данных, облачным сервисам, социальным сетям и т.д.\n",
    "- **Функции для обработки данных:** Парсинг текста, работа с файлами, выполнение математических операций.\n",
    "- **Взаимодействие с базами знаний:** Поиск информации в базе данных, извлечение данных из документов.\n",
    "\n",
    "#### Retriever (Известитель)\n",
    "\n",
    "**Retriever** — это компонент агента, отвечающий за извлечение релевантной информации из базы знаний или других источников данных. Retriever обычно использует различные методы для поиска и ранжирования документов, таких как:\n",
    "\n",
    "- **Поиск по ключевым словам:** Простой поиск по тексту.\n",
    "- **Векторное представление текста:** Использование моделей, таких как BERT, для создания векторных представлений текста и поиска наиболее похожих документов.\n",
    "- **Инвертированные индексы:** Создание индексов для быстрого поиска.\n",
    "\n",
    "### Пример написания агента на Python\n",
    "\n",
    "Давайте создадим простого агента, который будет взаимодействовать с базой знаний, состоящей из текстовых документов. Агент будет использовать Retriever для поиска релевантных документов и простую модель для формирования ответов.\n",
    "\n",
    "#### Шаг 1: Подготовка базы знаний\n",
    "\n",
    "Создадим несколько текстовых документов для базы знаний.\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    \"RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\",\n",
    "    \"Агент — это программа, способная автономно выполнять задачи, принимать решения и взаимодействовать с окружающей средой.\",\n",
    "    \"Python — высокоуровневый язык программирования, широко используемый для разработки веб-приложений, анализа данных и машинного обучения.\"\n",
    "]\n",
    "```\n",
    "\n",
    "#### Шаг 2: Создание Retriever\n",
    "\n",
    "Используем простой метод поиска по ключевым словам для Retriever.\n",
    "\n",
    "```python\n",
    "def simple_retriever(query, documents, top_k=1):\n",
    "    results = []\n",
    "    for doc in documents:\n",
    "        if query.lower() in doc.lower():\n",
    "            results.append(doc)\n",
    "    return results[:top_k]\n",
    "```\n",
    "\n",
    "#### Шаг 3: Создание простой модели для формирования ответов\n",
    "\n",
    "Используем простую модель, которая будет возвращать найденный документ как ответ.\n",
    "\n",
    "```python\n",
    "def simple_reader(retrieved_docs):\n",
    "    if retrieved_docs:\n",
    "        return retrieved_docs[0]\n",
    "    else:\n",
    "        return \"Извините, я не смог найти информацию на этот вопрос.\"\n",
    "```\n",
    "\n",
    "#### Шаг 4: Создание агента\n",
    "\n",
    "Создадим класс `Agent`, который будет использовать Retriever и Reader для ответа на вопросы.\n",
    "\n",
    "```python\n",
    "class Agent:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        return simple_retriever(query, self.documents)\n",
    "\n",
    "    def read(self, retrieved_docs):\n",
    "        return simple_reader(retrieved_docs)\n",
    "\n",
    "    def answer_question(self, query):\n",
    "        retrieved_docs = self.retrieve(query)\n",
    "        answer = self.read(retrieved_docs)\n",
    "        return answer\n",
    "```\n",
    "\n",
    "#### Шаг 5: Тестирование агента\n",
    "\n",
    "Теперь протестируем нашего агента, задав ему вопросы.\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    # Создание базы знаний\n",
    "    documents = [\n",
    "        \"RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\",\n",
    "        \"Агент — это программа, способная автономно выполнять задачи, принимать решения и взаимодействовать с окружающей средой.\",\n",
    "        \"Python — высокоуровневый язык программирования, широко используемый для разработки веб-приложений, анализа данных и машинного обучения.\"\n",
    "    ]\n",
    "\n",
    "    # Создание агента\n",
    "    agent = Agent(documents)\n",
    "\n",
    "    # Задание вопросов агенту\n",
    "    questions = [\n",
    "        \"Что такое RAG?\",\n",
    "        \"Что делает агент?\",\n",
    "        \"Что такое Python?\"\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"Вопрос: {question}\")\n",
    "        print(f\"Ответ: {agent.answer_question(question)}\\n\")\n",
    "```\n",
    "\n",
    "#### Вывод\n",
    "\n",
    "При запуске этого кода вы получите следующий вывод:\n",
    "\n",
    "```\n",
    "Вопрос: Что такое RAG?\n",
    "Ответ: RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\n",
    "\n",
    "Вопрос: Что делает агент?\n",
    "Ответ: Агент — это программа, способная автономно выполнять задачи, принимать решения и взаимодействовать с окружающей средой.\n",
    "\n",
    "Вопрос: Что такое Python?\n",
    "Ответ: Python — высокоуровневый язык программирования, широко используемый для разработки веб-приложений, анализа данных и машинного обучения.\n",
    "```\n",
    "\n",
    "### Расширение функционала агента\n",
    "\n",
    "Для более продвинутого агента можно использовать более сложные методы Retriever и Reader, такие как:\n",
    "\n",
    "- **Векторные представления текста:** Использование моделей, таких как BERT, для создания векторных представлений текста и поиска наиболее похожих документов.\n",
    "- **Модели генерации текста:** Использование моделей, таких как GPT или T5, для формирования более точных и естественно звучащих ответов.\n",
    "\n",
    "### Пример расширенного агента с использованием векторных представлений\n",
    "\n",
    "Для более продвинутого Retriever можно использовать библиотеку `sentence-transformers` для создания векторных представлений текста.\n",
    "\n",
    "#### Установка необходимых библиотек\n",
    "\n",
    "```bash\n",
    "pip install sentence-transformers\n",
    "```\n",
    "\n",
    "#### Код расширенного агента\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Создание базы знаний\n",
    "documents = [\n",
    "    \"RAG — это архитектура, которая сочетает извлечение информации и её чтение для точного ответа на вопросы.\",\n",
    "    \"Агент — это программа, способная автономно выполнять задачи, принимать решения и взаимодействовать с окружающей средой.\",\n",
    "    \"Python — высокоуровневый язык программирования, широко используемый для разработки веб-приложений, анализа данных и машинного обучения.\"\n",
    "]\n",
    "\n",
    "# Инициализация модели для создания векторных представлений\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Создание векторных представлений для документов\n",
    "doc_embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "class AdvancedAgent:\n",
    "    def __init__(self, documents, doc_embeddings, model):\n",
    "        self.documents = documents\n",
    "        self.doc_embeddings = doc_embeddings\n",
    "        self.model = model\n",
    "\n",
    "    def retrieve(self, query, top_k=1):\n",
    "        # Создание векторного представления запроса\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        # Поиск наиболее похожих документов\n",
    "        hits = util.semantic_search(query_embedding, self.doc_embeddings, top_k=top_k)[0]\n",
    "        retrieved_docs = [self.documents[hit['corpus_id']] for hit in hits]\n",
    "        return retrieved_docs\n",
    "\n",
    "    def read(self, retrieved_docs):\n",
    "        if retrieved_docs:\n",
    "            return retrieved_docs[0]\n",
    "        else:\n",
    "            return \"Извините, я не смог найти информацию на этот вопрос.\"\n",
    "\n",
    "    def answer_question(self, query):\n",
    "        retrieved_docs = self.retrieve(query)\n",
    "        answer = self.read(retrieved_docs)\n",
    "        return answer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Инициализация агента\n",
    "    agent = AdvancedAgent(documents, doc_embeddings, model)\n",
    "\n",
    "    # Задание вопросов агенту\n",
    "    questions = [\n",
    "        \"Что такое RAG?\",\n",
    "        \"Что делает агент?\",\n",
    "        \"Что такое Python?\"\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"Вопрос: {question}\")\n",
    "        print(f\"Ответ: {agent.answer_question(question)}\\n\")\n",
    "```\n",
    "\n",
    "#### Вывод\n",
    "\n",
    "Этот расширенный агент использует векторные представления для более точного поиска релевантных документов, что позволяет улучшить качество ответов.\n",
    "\n",
    "### Заключение\n",
    "\n",
    "Агенты играют важную роль в автоматизации задач и взаимодействии с пользователями. Они могут использовать различные инструменты и компоненты, такие как Retriever для поиска информации и Reader для формирования ответов. В данном примере мы рассмотрели, как создать простого агента на Python, используя базовые методы поиска и расширенные методы с использованием векторных представлений текста. Вы можете расширять функциональность агента, добавляя новые инструменты и улучшая методы поиска и анализа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4fc75-9e6d-4392-911a-9c67f89df348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab560a-756b-4d05-8464-2ce256d068c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473929df-16fa-4a46-9d77-29cf7b7e8341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
