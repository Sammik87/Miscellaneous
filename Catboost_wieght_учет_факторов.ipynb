{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6d17f1-39bb-4c5a-8e83-a22267ef42a7",
   "metadata": {},
   "source": [
    "# Catboost wieght и учет факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5b666-cbb6-4f3d-9481-fc56044852e7",
   "metadata": {},
   "source": [
    "Вместо удаления дорогих квартир, попробуйте использовать взвешивание данных при обучении модели CatBoost.  Присвойте большим весам данные из элитного сегмента.  Это позволит модели уделять больше внимания этим данным и лучше их \"запоминать\".  CatBoost позволяет задавать веса наблюдений через параметр sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0320dfa-88ef-4fbf-8e50-e46728278e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "#  Создаем веса.  Например,  увеличиваем вес для элитных квартир в 5 раз\n",
    "weights = np.where(df['статус жк'] == 'элитный', 5, 1)\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000,  # другие параметры\n",
    "                         loss_function='RMSE',\n",
    "                         verbose=100,\n",
    "                         cat_features=categorical_features)\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c3432-a7f9-4a95-8614-aa1db45da8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb586540-5b63-438d-99a6-e31340320ee8",
   "metadata": {},
   "source": [
    "1. Пропорциональное взвешивание:\n",
    "Этот подход нацелен на балансировку классов, придавая больший вес менее представленным классам.  Вычисляем обратную частоту каждого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0638dee-ae91-4d85-97b8-6bfb7c8c111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Подсчет количества объектов в каждом классе\n",
    "class_counts = df['статус ЖК'].value_counts()\n",
    "\n",
    "# Вычисление весов, обратных частотам\n",
    "weights = 1.0 / class_counts[df['статус ЖК']]\n",
    "\n",
    "# Применение весов\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features)\n",
    "model.fit(X_train, y_train, sample_weight=weights.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32356f9b-e77c-4aac-8dd8-db67efecd76e",
   "metadata": {},
   "source": [
    "2.  Взвешивание на основе вашей экспертной оценки:\n",
    "Если у вас есть экспертная информация о важности каждого класса для модели,  вы можете задать веса вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b90bac-2bdf-4ee4-87f5-b2a2de261044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем веса вручную, например:\n",
    "weights_dict = {'нет': 1, 'престижный': 2, 'престижный+': 5}  # 'престижный+' имеет наибольший вес\n",
    "\n",
    "weights = df['статус ЖК'].map(weights_dict)\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features)\n",
    "model.fit(X_train, y_train, sample_weight=weights.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97da309-c8d3-4454-94f4-91f23dd3eb52",
   "metadata": {},
   "source": [
    "3.  Комбинированный подход:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de133d94-1dce-40ef-9156-14b05b4e498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['статус ЖК'].value_counts()\n",
    "weights = 1.0 / class_counts[df['статус ЖК']]\n",
    "\n",
    "expert_weights = {'нет': 1, 'престижный': 1.2, 'престижный+': 1.5} # коэффициенты экспертной оценки\n",
    "weights = weights * df['статус ЖК'].map(expert_weights)\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=weights.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee266e-50a3-4bd1-946a-1bec78303b14",
   "metadata": {},
   "source": [
    "CatBoost использует эти веса для каждого наблюдения в обучающей выборке, но только в контексте частоты встречаемости категорий в столбце \"статус ЖК\".  Для других признаков веса не применяются."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36209c48-d658-4fdb-a974-7237b9cd6664",
   "metadata": {},
   "source": [
    "1. Взвешивание по каждому признаку отдельно, затем усреднение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960655e-2a49-453a-b5d1-3dfb8cc1457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Взвешивание для \"статус ЖК\"\n",
    "class_counts_status = df['статус ЖК'].value_counts()\n",
    "weights_status = 1.0 / class_counts_status[df['статус ЖК']]\n",
    "\n",
    "# Взвешивание для \"до мкад/за мкад\"\n",
    "class_counts_mkad = df['до мкад/за мкад'].value_counts()\n",
    "weights_mkad = 1.0 / class_counts_mkad[df['до мкад/за мкад']]\n",
    "\n",
    "# Усреднение весов (можно использовать другие методы агрегации, например, геометрическое среднее)\n",
    "weights = (weights_status + weights_mkad) / 2\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features)\n",
    "model.fit(X_train, y_train, sample_weight=weights.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38876c-3ac9-4c34-a0ef-d1a1d8127917",
   "metadata": {},
   "source": [
    "2.  Взвешивание по комбинациям признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d634b-1e34-41a6-81e8-49ee4813a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Создаем новый столбец с комбинацией категорий\n",
    "df['комбинация'] = df['статус ЖК'] + '_' + df['до мкад/за мкад']\n",
    "\n",
    "# Взвешивание по комбинациям\n",
    "class_counts_combo = df['комбинация'].value_counts()\n",
    "weights_combo = 1.0 / class_counts_combo[df['комбинация']]\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features)\n",
    "model.fit(X_train, y_train, sample_weight=weights_combo.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36a976-5b62-44e3-b2e2-c72050483194",
   "metadata": {},
   "source": [
    "Этот метод создаёт новый признак, представляющий собой комбинацию значений из \"статус ЖК\" и \"до мкад/за мкад\", и затем вычисляет веса на основе частоты встречаемости этих комбинаций.  Этот подход лучше, чем простое усреднение, потому что он учитывает взаимосвязь между признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c3847-abd4-4246-acab-d9a60d61ab28",
   "metadata": {},
   "source": [
    "3.  Использование экспертных знаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d2217-5f4a-4c37-bdb3-b06e62430107",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_table = {\n",
    "    ('нет', 'внутри мкад'): 1,\n",
    "    ('нет', 'за мкад'): 0.8,\n",
    "    ('престижный', 'внутри мкад'): 3,\n",
    "    ('престижный', 'за мкад'): 2,\n",
    "    ('престижный+', 'внутри мкад'): 5,\n",
    "    ('престижный+', 'за мкад'): 4,\n",
    "    # ... другие комбинации ...\n",
    "}\n",
    "weights = df.apply(lambda row: weight_table[(row['статус ЖК'], row['до мкад/за мкад'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45143c-858c-4044-a346-10ceba5b35cd",
   "metadata": {},
   "source": [
    "1. Валидация и веса:\n",
    "\n",
    "Вы правы, при обучении модели CatBoost в метод fit веса добавляются только для обучающей выборки (X_train, y_train).  Валидационная выборка (которую CatBoost использует внутренне для ранней остановки и предотвращения переобучения) не использует эти веса.  CatBoost сам управляет внутренней валидацией; вы не передаете веса для валидационной выборки в fit.\n",
    "\n",
    "\n",
    "2. Хранение весов в модели:\n",
    "\n",
    "Обученная модель CatBoost  не хранит  веса, используемые во время обучения. Веса используются только в процессе обучения для корректировки функции потерь. После обучения модель представляет собой набор параметров (например, веса деревьев в градиентном бустинге), которые оптимально аппроксимируют зависимость между признаками и целевой переменной, учитывая данные с весами.\n",
    "\n",
    "\n",
    "3. Удаление признака \"статус ЖК\":\n",
    "\n",
    "Вы правильно заметили, что в примере я убрал признак \"статус ЖК\" из X  (X = df.drop(['цена', 'статус ЖК'], axis=1)).  Это сделано потому, что веса, которые мы вычисляем, основаны на распределении категорий именно в этом признаке.  Если оставить \"статус ЖК\" в X, то модель будет использовать его как обычный признак, и это может привести к дублированию информации и проблемам с обучением.  Модель будет пытаться учитывать вклад \"статус ЖК\" дважды: как обычный категориальный признак и неявно, через веса, что исказит результаты.\n",
    "\n",
    "\n",
    "4. Расчет метрик и веса:\n",
    "\n",
    "Вы правы, при расчете метрик на тестовой выборке веса не используются.  Метрики должны отражать обобщающую способность модели на новых, невиденных данных, независимо от весов, использованных при обучении.\n",
    "\n",
    "\n",
    "5. Как модель \"знает\" веса (после drop):\n",
    "\n",
    "Модель  не \"знает\"  веса после обучения.  Веса применяются только во время процесса обучения для изменения функции потерь и, следовательно, влияния на подбор оптимальных параметров модели.  После обучения веса не используются.  Прогнозы на тестовых и новых данных делаются с помощью обученной модели без учёта весов, используемых при обучении.\n",
    "\n",
    "\n",
    "Исправленный код (без удаления \"статус ЖК\"):\n",
    "\n",
    "В действительности, удаление 'статус ЖК' не всегда необходимо.  Если вы хотите, чтобы модель учитывала 'статус ЖК' как обычный предиктор, то лучше оставить его. В этом случае вы будете использовать веса для балансировки классов, а не для изменения влияния признака \"статус ЖК\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131614d-e66a-4bcf-b23e-8976cbb36b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ... (загрузка данных и вычисление весов - как в предыдущем примере) ...\n",
    "\n",
    "# Разделение признаков (X) и целевой переменной (y) -  'статус ЖК' ОСТАЕТСЯ\n",
    "X = df.drop('цена', axis=1)\n",
    "y = df['цена']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(\n",
    "    X, y, weights, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "categorical_features_indices = [X.columns.get_loc(col) for col in ['район', 'округ', 'город/область', 'до мкад/за мкад', 'статус ЖК']]\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "# ... (прогнозирование и расчет метрик - как в предыдущем примере) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e795f-02d7-4a45-8001-e2f1b842dd10",
   "metadata": {},
   "source": [
    "Существует несколько способов учесть информацию о двух \"сверх-элитных\" ЖК в вашей модели CatBoost, чтобы улучшить прогнозирование цен для них. Ключевая идея — добавить информацию о дополнительной категории элитности или создать новые признаки, которые бы отражали особенности этих ЖК."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bda4c8-92f8-4700-847a-df9a2b5e20d5",
   "metadata": {},
   "source": [
    "Метод 1: Добавление новой категории в фактор \"статус ЖК\"\n",
    "\n",
    "Самый простой и понятный способ — добавить новую категорию в фактор \"статус ЖК\", например, \"престиж++\". Это позволит модели напрямую выучить специфику ценообразования для этой новой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bdb68-58b8-45ee-8141-953484c39202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных и создание модели - как в предыдущих примерах) ...\n",
    "\n",
    "# Идентификация сверх-элитных ЖК (замените на ваши условия)\n",
    "super_elite_zhk = ['ЖК1', 'ЖК2']  # Названия или ID сверх-элитных ЖК\n",
    "\n",
    "# Добавление новой категории\n",
    "df['статус ЖК'] = df['статус ЖК'].apply(lambda x: 'престиж++' if df['Название ЖК'].isin(super_elite_zhk) else x)\n",
    "\n",
    "\n",
    "# Обновление списка категориальных признаков (очень важно!)\n",
    "categorical_features_indices = [df.columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "# Обучение модели (с обновленными категориями)\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight = weights_train) # weights_train - Ваши веса, если используются\n",
    "#... (прогнозирование и оценка)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79036b-c824-4056-a804-df315dd0535a",
   "metadata": {},
   "source": [
    "Метод 2: Создание новых признаков\n",
    "\n",
    "Вместо добавления категории, можно создать новые бинарные признаки, которые указывают на принадлежность к этим двум ЖК."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5117b-31f2-44be-b441-cb77c5d7f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "# ... (Загрузка данных и создание модели - как в предыдущих примерах) ...\n",
    "\n",
    "# Создание новых признаков\n",
    "df['ЖК1'] = df['Название ЖК'].apply(lambda x: 1 if x == 'ЖК1' else 0)\n",
    "df['ЖК2'] = df['Название ЖК'].apply(lambda x: 1 if x == 'ЖК2' else 0)\n",
    "\n",
    "# Обучение модели (с новыми признаками)\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100) # cat_features может не понадобиться, если новые признаки числовые\n",
    "model.fit(X_train, y_train, sample_weight = weights_train) # weights_train - Ваши веса, если используются\n",
    "\n",
    "#... (прогнозирование и оценка)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d0259-862f-41d5-8548-8dcb94f8ffb0",
   "metadata": {},
   "source": [
    "Метод 3: Использование взвешивания (более сложный вариант):\n",
    "\n",
    "Можно попробовать использовать взвешивание, но не просто для классов \"статус ЖК\", а для отдельных объектов. Если вы уверены, что данные по этим двум ЖК особенно важны, можно присвоить им значительно больший вес в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379737b-3f88-433a-af74-8012163e4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных и создание модели - как в предыдущих примерах) ...\n",
    "\n",
    "# Взвешивание данных\n",
    "weights = np.ones(len(df))\n",
    "weights[df['Название ЖК'].isin(super_elite_zhk)] = 10  # Увеличиваем вес для сверх-элитных ЖК в 10 раз\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100)\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# ... (прогнозирование и оценка)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dd100-6a38-429d-960e-0acdbb324bae",
   "metadata": {},
   "source": [
    "Метод 4: Комбинация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539d4ba-2a6f-4d96-8f60-79268fbc661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных и создание модели - как в предыдущих примерах) ...\n",
    "\n",
    "# Идентификация сверх-элитных ЖК\n",
    "super_elite_zhk = ['ЖК1', 'ЖК2']\n",
    "\n",
    "# Добавление новой категории\n",
    "df['статус ЖК'] = df['статус ЖК'].apply(lambda x: 'престиж++' if df['Название ЖК'].isin(super_elite_zhk) else x)\n",
    "\n",
    "# Обновление списка категориальных признаков\n",
    "categorical_features_indices = [df.columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "# Задание весов\n",
    "weights_dict = {'нет': 1, 'престижный': 2, 'престижный+': 3, 'престиж++': 5}\n",
    "weights = df['статус ЖК'].map(weights_dict)\n",
    "\n",
    "# Обучение модели\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# ... (прогнозирование и оценка) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c856d32-87e7-4283-932d-a90c421e7562",
   "metadata": {},
   "source": [
    "Важные замечания:\n",
    "\n",
    "• Выбор весов:  Веса 1, 2, 3, 5 — это пример.  Вам, возможно, потребуется экспериментировать с разными значениями весов, чтобы найти оптимальное соотношение.  Начните с небольших различий в весах и постепенно увеличивайте, следя за качеством прогноза.\n",
    "• Оценка качества:  Тщательно отслеживайте качество модели на тестовой выборке после внесения изменений.  Убедитесь, что комбинированный подход (добавление категории + взвешивание) действительно улучшает качество прогнозирования, особенно для сверх-элитных ЖК.  Не исключено, что простого добавления категории \"престиж++\" будет достаточно.\n",
    "• Переобучение:  Чрезмерное взвешивание может привести к переобучению.  Обращайте внимание на метрики качества на тестовой выборке.\n",
    "• Feature Importance:  После обучения модели, посмотрите на feature_importances_.  Это поможет понять, насколько эффективно модель использует новый признак и веса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b03758-587f-4559-ad3e-79f7373a1b22",
   "metadata": {},
   "source": [
    "Реализация расчета веса через средние значения удельной цены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cd927-8bb4-474e-ac12-ba7fd0e8dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных, добавление категории \"престиж++\", как в предыдущем примере) ...\n",
    "\n",
    "# Расчет удельной цены за кв.м для каждой категории\n",
    "df['цена_кв_м'] = df['цена'] / df['площадь']\n",
    "\n",
    "# Группировка данных по \"статус ЖК\" и расчет средней удельной цены\n",
    "avg_prices = df.groupby('статус ЖК')['цена_кв_м'].mean()\n",
    "\n",
    "# Расчет доли каждой категории в общей сумме цен\n",
    "total_price = avg_prices.sum()\n",
    "weights = avg_prices / total_price\n",
    "\n",
    "# Применение весов к данным\n",
    "weights_series = df['статус ЖК'].map(weights)\n",
    "\n",
    "# Обучение модели CatBoost\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight=weights_series)\n",
    "\n",
    "# ... (прогнозирование и оценка) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe5aab-2482-485f-816c-010b44572ca0",
   "metadata": {},
   "source": [
    "Минусы среднего:\n",
    "\n",
    "• Чувствительность к выбросам:  Если в какой-либо категории есть несколько очень дорогих квартир (выбросы), это может сильно исказить среднюю удельную цену и, следовательно, вес этой категории.  Это может привести к переобучению модели на выбросах.\n",
    "• Зависимость от распределения:  Веса сильно зависят от распределения цен в каждой категории.  Если распределение цен сильно асимметричное, то средняя цена может быть не очень представительной.\n",
    "• Неучет других факторов:  Этот метод учитывает только удельную цену, игнорируя другие важные факторы, которые могут влиять на цену квартиры (например, расположение, год постройки, состояние)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8692e2-2e46-4658-b7f3-639a7e0d2359",
   "metadata": {},
   "source": [
    "Плюсы использования медианы:\n",
    "\n",
    "• Устойчивость к выбросам: Главное преимущество медианы – её устойчивость к выбросам. В отличие от среднего, медиана не сильно меняется при наличии экстремальных значений. В данных о ценах на недвижимость выбросы (очень дорогие или очень дешевые квартиры) встречаются часто, и использование медианы помогает сгладить их влияние на расчет весов. Это делает модель более устойчивой к искажениям, вызванным аномальными значениями.\n",
    "• Более представительная оценка: В случае асимметричных распределений цен медиана часто является более представительной мерой центральной тенденции, чем среднее. Среднее может быть сильно смещено в сторону выбросов, тогда как медиана остается ближе к типичным значениям.\n",
    "• Проще интерпретировать: Медиана проще интерпретируется, чем среднее, особенно для неспециалистов. Медиана — это значение, которое делит выборку пополам.\n",
    "\n",
    "\n",
    "Минусы использования медианы:\n",
    "\n",
    "• Меньшая чувствительность к изменениям: Медиана менее чувствительна к изменениям в данных, чем среднее. Если есть небольшие, но систематические изменения в ценах, среднее будет их отражать лучше, чем медиана.\n",
    "• Более сложные вычисления: В некоторых случаях расчет медианы может быть немного сложнее, чем среднего, хотя в Python это не составляет проблемы.\n",
    "• Потеря информации: Использование медианы означает, что мы игнорируем часть информации о распределении цен. Среднее учитывает все значения, тогда как медиана фокусируется только на центральной части распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2ecbe-1366-40a4-ae59-ad7efe0d9b1c",
   "metadata": {},
   "source": [
    "Взвешивание на основе квантилей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bd732-0e3c-4304-b00c-9f6d648ee63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных, добавление категории \"престиж++\") ...\n",
    "\n",
    "def quantile_weights(df, column, n_quantiles=10):\n",
    "    \"\"\"Вычисляет веса на основе квантилей.\"\"\"\n",
    "    quantiles = pd.qcut(df[column], q=n_quantiles, labels=False, duplicates='drop')\n",
    "    weights = (n_quantiles - quantiles) / n_quantiles #Квантили ближе к максимуму получают больший вес\n",
    "    return weights\n",
    "\n",
    "# Расчет весов на основе квантилей цены\n",
    "weights = quantile_weights(df, 'цена')\n",
    "\n",
    "# Обучение модели CatBoost\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# ... (прогнозирование и оценка) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e54d7-7a44-4c61-82eb-603639c02ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ... (Загрузка данных, добавление категории \"престиж++\") ...\n",
    "\n",
    "def quantile_weights_by_category(df, column, category_column, n_quantiles=10):\n",
    "    \"\"\"Вычисляет веса на основе квантилей для каждой категории.\"\"\"\n",
    "    weights = []\n",
    "    for category in df[category_column].unique():\n",
    "        df_subset = df[df[category_column] == category]\n",
    "        quantiles = pd.qcut(df_subset[column], q=n_quantiles, labels=False, duplicates='drop')\n",
    "        category_weights = (n_quantiles - quantiles) / n_quantiles  #Высшие квантили получают больший вес\n",
    "        weights.extend(category_weights.tolist())\n",
    "    return np.array(weights)\n",
    "\n",
    "\n",
    "# Расчет весов на основе квантилей цены для каждой категории \"статус ЖК\"\n",
    "weights = quantile_weights_by_category(df, 'цена', 'статус ЖК', n_quantiles=10)\n",
    "\n",
    "# Обучение модели CatBoost\n",
    "model = CatBoostRegressor(iterations=1000, loss_function='RMSE', verbose=100, cat_features=categorical_features_indices)\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# ... (прогнозирование и оценка) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf6703-6396-4399-b85d-d2ffd53c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 1. Определение функции для назначения весов на основе ценового диапазона\n",
    "def get_weight(price):\n",
    "    if price <= 3000000:  # До 3 млн\n",
    "        return 0.5  # Понижаем вес, так как переоцениваются\n",
    "    elif price >= 20000000:  # От 20 млн\n",
    "        return 2.0  # Увеличиваем вес, так как недооцениваются\n",
    "    else:\n",
    "        return 1.0  # Оставляем без изменений\n",
    "\n",
    "# 2. Создание списка весов для каждой записи в обучающих данных\n",
    "train_weights = [get_weight(price) for price in y_train]\n",
    "\n",
    "# 3. Обучение модели CatBoostRegressor с использованием sample_weight\n",
    "model = CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    loss_function='RMSE',  # или другая подходящая функция потерь для регрессии\n",
    "    eval_metric='RMSE',  # или другая метрика для оценки\n",
    "    verbose=False, # Отключаем вывод информации во время обучения\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, verbose=False, sample_weight=train_weights)\n",
    "\n",
    "# 4. Оценка модели на отложенной выборке (validation)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Рассчет метрик на разных диапазонах цен для анализа смещения.\n",
    "# (Пример)\n",
    "def calculate_metrics_by_price_range(y_true, y_pred, price_ranges):\n",
    "    metrics = {}\n",
    "    for lower_bound, upper_bound in price_ranges:\n",
    "        # Находим индексы квартир, попадающих в этот диапазон\n",
    "        indices = np.where((y_true >= lower_bound) & (y_true < upper_bound))[0]\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            # Выбираем только те значения, которые попадают в диапазон\n",
    "            y_true_range = y_true[indices]\n",
    "            y_pred_range = y_pred[indices]\n",
    "\n",
    "            # Рассчитываем метрики (например, MAE, RMSE)\n",
    "            mae = np.mean(np.abs(y_true_range - y_pred_range))\n",
    "            rmse = np.sqrt(np.mean((y_true_range - y_pred_range)**2))\n",
    "\n",
    "            metrics[f\"{lower_bound}-{upper_bound}\"] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "        else:\n",
    "            metrics[f\"{lower_bound}-{upper_bound}\"] = \"No data in range\"\n",
    "\n",
    "    return metrics\n",
    "\n",
    "price_ranges = [\n",
    "    (0, 3000000),\n",
    "    (3000000, 6000000),\n",
    "    (6000000, 9000000),\n",
    "    (9000000, 12000000),\n",
    "    (12000000, 15000000),\n",
    "    (15000000, 20000000),\n",
    "    (20000000, float('inf'))  # Бесконечность для цен выше 20 млн\n",
    "]\n",
    "\n",
    "metrics_by_range = calculate_metrics_by_price_range(y_val, y_pred, price_ranges)\n",
    "print(\"Метрики по диапазонам цен:\\n\", metrics_by_range)\n",
    "\n",
    "# 5. Анализ результатов и итеративное изменение весов\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458556d2-64c6-46c6-ba9b-0067f55d7c3c",
   "metadata": {},
   "source": [
    "1. get_weight(price): Функция, которая принимает цену квартиры и возвращает соответствующий вес. Внутри функции определяется логика назначения весов в зависимости от ценового диапазона. Этот код присваивает вес 0.5 квартирам до 3 млн, вес 2.0 квартирам от 20 млн и вес 1.0 всем остальным. Вы можете настроить эту функцию в соответствии с вашими потребностями.\n",
    "\n",
    "2. train_weights: Создается список весов для каждой квартиры в обучающем наборе данных. Этот список создается путем итерации по y_train (который содержит фактические цены квартир) и применения функции get_weight() к каждой цене.\n",
    "\n",
    "3. CatBoostRegressor(sample_weight=train_weights): При обучении модели CatBoostRegressor мы передаем список train_weights в аргумент sample_weight функции fit(). Это указывает CatBoost использовать эти веса при обучении.\n",
    "\n",
    "•   Вес 1 (1.0): Вес 1 означает, что данному образцу (строке данных) уделяется *стандартное*, или *обычное*, внимание при обучении модели. Это как если бы вы не использовали sample_weight вообще. Образцы с весом 1 рассматриваются как \"типичные\" или \"представительные\" данные.  Их вклад в функцию потерь будет соответствовать их ошибке, без какого-либо увеличения или уменьшения.\n",
    "\n",
    "Пояснение в контексте ваших данных о квартирах:\n",
    "\n",
    "•   Если вы присваиваете вес 1 квартирам в ценовом диапазоне \"от 6 до 9 миллионов рублей\", это означает, что вы не хотите специально \"толкать\" модель к тому, чтобы она лучше или хуже предсказывала цены этих квартир, по сравнению с тем, как она это делала бы без использования sample_weight.  Вы считаете, что модель уже достаточно хорошо работает с этим ценовым диапазоном, или что у вас нет оснований уделять этим квартирам больше или меньше внимания.\n",
    "\n",
    "Аналогия:\n",
    "\n",
    "Представьте, что вы учитель, и у вас есть группа учеников.\n",
    "\n",
    "•   Вес > 1 (например, 2): Это как если бы вы решили уделить *больше* внимания конкретному ученику, потому что он испытывает трудности с определенной темой, или потому что он очень талантлив и вы хотите помочь ему раскрыть свой потенциал.\n",
    "•   Вес < 1 (например, 0.5): Это как если бы вы решили уделить *меньше* внимания ученику, потому что он уже хорошо справляется с материалом, или потому что он отвлекает других учеников в классе.\n",
    "•   Вес 1: Это как если бы вы относились к ученику как к *обычному* ученику, уделяя ему стандартное количество внимания.\n",
    "\n",
    "Ключевой момент:\n",
    "\n",
    "Важно помнить, что веса — это *относительные* значения. Значение имеет не абсолютное значение веса (например, 2), а его *отношение* к другим весам в вашем наборе данных.  Если бы вы умножили все веса на 2, то это, вероятно, не оказало бы никакого эффекта на обучение модели (если только это не привело бы к численным проблемам).  Важно, чтобы разница между весами отражала вашу уверенность в том, насколько важно для модели правильно предсказывать разные типы образцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db03715-cbbe-4702-8754-c5518e787e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
