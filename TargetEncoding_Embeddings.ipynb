{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7576269-c959-4c1d-817a-10bddd940ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6f2be-6afc-4575-8fb1-a761e80a7843",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef298c-e96a-48fa-b375-54608e8410b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Применение target encoding\n",
    "categorical_features = ['этаж расположения', 'состояние отделки', 'район расположения', 'статус ЖК', 'расстояние до метро']\n",
    "encoder = TargetEncoder()\n",
    "df_encoded = df.copy()\n",
    "df_encoded[categorical_features] = encoder.fit_transform(df[categorical_features], df['цена'])\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e18870-e626-42da-958f-1064f590a89d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de51a9-e8f0-4df1-b9d0-4d1f31134335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Пример категориального признака\n",
    "num_categories = len(df['район расположения'].unique())\n",
    "embedding_dim = 5  # Размерность вектора\n",
    "\n",
    "# Вход для района\n",
    "input_layer = Input(shape=(1,))\n",
    "embedding_layer = Embedding(input_dim=num_categories, output_dim=embedding_dim, input_length=1)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "# Создание модели\n",
    "model = Model(inputs=input_layer, outputs=flatten_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Кодирование категорий\n",
    "encoded_values = model.predict(df['район расположения'])\n",
    "print(encoded_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c33cbb84-ba6c-428a-8ab1-938cd97c395b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n",
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.7772 \n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.7643\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.9173\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4970\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.4742\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.4743\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4633\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4522\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1730\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.1690\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.3950\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.3821\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8106\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.3818\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.7901\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6000\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6647\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7577\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.5641\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.9689\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.3071\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.2954\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7020\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5023\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6788\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6670\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.4636\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.5219\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6231\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.9073\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8933\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.4677\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1609\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1488\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8508\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.5474\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1109\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.0148\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4936\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.4969\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.7499\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.4712\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7388\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6404\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.6887\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.0121\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.5956\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.6421\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.1591\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6364\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.3519\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.9059\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.3241\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4867\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4701\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.4536\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.4944\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6806\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8362\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9879\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7717\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4485\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.7410\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.4154\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.5542\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.0922\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.0761\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.9074\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.2819\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8726\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.0585\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.1838\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.2138\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.2467\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.2294\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.9267\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9095\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1210\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8750\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.0389\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4496\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8237\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.0456\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8515\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8346\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8175\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.9058\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.9940\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.7653\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.3607\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.8252\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3265\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4354\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.5988\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7423\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7575\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7370\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7168\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.2096\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.6775\n",
      "\n",
      "Embeddings районов:\n",
      "      emb_0     emb_1     emb_2   district\n",
      "0  0.124303  0.133199  0.035645      Центр\n",
      "1 -0.163708 -0.120763 -0.150659      Южный\n",
      "2 -0.215306 -0.241622 -0.251238   Северный\n",
      "3 -0.149018 -0.125464 -0.219276   Западный\n",
      "4 -0.124578 -0.128981 -0.170770  Восточный\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Создаем DataFrame с районами\n",
    "data = pd.DataFrame({\n",
    "    'district': ['Центр', 'Южный', 'Северный', 'Западный', 'Восточный', 'Центр', 'Южный', 'Северный']\n",
    "})\n",
    "\n",
    "# Присваиваем индекс для районов (НЕ LabelEncoder!)\n",
    "unique_districts = data['district'].unique()\n",
    "district_to_idx = {district: idx for idx, district in enumerate(unique_districts)}\n",
    "data['district_encoded'] = data['district'].map(district_to_idx)\n",
    "\n",
    "# Подготовка входных данных\n",
    "X_train, X_test = train_test_split(data['district_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Определяем параметры embeddings\n",
    "num_districts = len(unique_districts)  # Количество районов\n",
    "embedding_dim = 3  # Размерность вектора embeddings\n",
    "\n",
    "# Определяем входные данные\n",
    "input_district = keras.layers.Input(shape=(1,))\n",
    "district_embedding = keras.layers.Embedding(input_dim=num_districts, output_dim=embedding_dim)(input_district)\n",
    "district_embedding = keras.layers.Flatten()(district_embedding)\n",
    "\n",
    "# Выходной слой (здесь просто обучаем embeddings, без предсказания)\n",
    "output = keras.layers.Dense(embedding_dim, activation='linear')(district_embedding)\n",
    "\n",
    "# Создаем модель\n",
    "model = keras.Model(inputs=input_district, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Обучаем embeddings\n",
    "model.fit(X_train, X_train, epochs=100, batch_size=4, verbose=1)\n",
    "\n",
    "# Извлекаем обученные embeddings\n",
    "embedding_weights = model.get_layer(index=1).get_weights()[0]\n",
    "\n",
    "# Создаем DataFrame с embeddings\n",
    "district_embeddings = pd.DataFrame(embedding_weights, columns=[f'emb_{i}' for i in range(embedding_dim)])\n",
    "district_embeddings['district'] = unique_districts\n",
    "\n",
    "print(\"\\nEmbeddings районов:\")\n",
    "print(district_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10745be-5cd5-485a-92b1-e0746fab5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Создаем искусственные данные (как раньше)\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "area = np.random.uniform(30, 150, n_samples)  # Площадь квартиры\n",
    "floor = np.random.randint(1, 20, n_samples)   # Этаж\n",
    "total_floors = np.random.randint(floor, floor + 10, n_samples)  # Этажность здания\n",
    "year_built = np.random.randint(1950, 2020, n_samples)  # Год постройки\n",
    "condition = np.random.choice(['good', 'average', 'bad'], n_samples)  # Состояние отделки\n",
    "\n",
    "condition_numeric = condition.map({'good': 3, 'average': 2, 'bad': 1})\n",
    "\n",
    "price = (\n",
    "    area * 1000 +\n",
    "    floor * 500 +\n",
    "    total_floors * 100 +\n",
    "    (2020 - year_built) * 300 +\n",
    "    condition_numeric * 1000\n",
    ")\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'area': area,\n",
    "    'floor': floor,\n",
    "    'total_floors': total_floors,\n",
    "    'year_built': year_built,\n",
    "    'condition': condition_numeric,\n",
    "    'price': price\n",
    "})\n",
    "\n",
    "# Добавляем информацию о районе\n",
    "districts = np.random.choice(['District1', 'District2', 'District3', 'District4', 'District5'], n_samples)  # Пример 5 районов\n",
    "data['district'] = districts\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Преобразуем категориальные признаки в числовые (one-hot encoding)\n",
    "X_encoded = {\n",
    "    'area': X['area'].values.reshape(-1, 1),\n",
    "    'floor': X['floor'].values.reshape(-1, 1),\n",
    "    'total_floors': X['total_floors'].values.reshape(-1, 1),\n",
    "    'year_built': X['year_built'].values.reshape(-1, 1),\n",
    "    'condition': X['condition'].values.reshape(-1, 1),\n",
    "    'district': pd.get_dummies(data['district']).values\n",
    "}\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем модель с эмбеддингами\n",
    "def create_model(input_dim, embedding_dim):\n",
    "    # Входные слои\n",
    "    area_input = Input(shape=(1,), name='area')\n",
    "    floor_input = Input(shape=(1,), name='floor')\n",
    "    total_floors_input = Input(shape=(1,), name='total_floors')\n",
    "    year_built_input = Input(shape=(1,), name='year_built')\n",
    "    condition_input = Input(shape=(1,), name='condition')\n",
    "    district_input = Input(shape=(1,), name='district')\n",
    "\n",
    "    # Эмбеддинги для категориальных признаков\n",
    "    district_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim)(district_input)\n",
    "    district_embedding = tf.squeeze(district_embedding, axis=1)\n",
    "\n",
    "    # Свертка эмбеддингов\n",
    "    district_dense = Dense(10, activation='relu')(district_embedding)\n",
    "\n",
    "    # Связывание всех входов\n",
    "    concatenated = concatenate([area_input, floor_input, total_floors_input, year_built_input, condition_input, district_dense])\n",
    "\n",
    "    # Полносвязные слои\n",
    "    dense1 = Dense(64, activation='relu')(concatenated)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    output = Dense(1)(dense2)\n",
    "\n",
    "    # Создаем модель\n",
    "    model = Model(inputs=[area_input, floor_input, total_floors_input, year_built_input, condition_input, district_input], outputs=output)\n",
    "\n",
    "    # Компиляция модели\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Определяем количество уникальных районов и размер эмбеддинга\n",
    "num_districts = len(data['district'].unique())\n",
    "embedding_dim = 5\n",
    "\n",
    "# Создаем модель\n",
    "model = create_model(num_districts, embedding_dim)\n",
    "\n",
    "# Обучаем модель\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Оцениваем модель на тренировочных данных\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}, Train MAPE: {train_mape:.2%}\")\n",
    "\n",
    "# Оцениваем модель на тестовых данных\n",
    "y_test_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, MAPE: {mape:.2%}\")\n",
    "\n",
    "# Извлечение эмбеддингов для районов\n",
    "embedding_layer = model.get_layer('embedding')\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Сохранение эмбеддингов в DataFrame\n",
    "embeddings_df = pd.DataFrame(embedding_weights, index=data['district'].unique())\n",
    "\n",
    "# Вывод эмбеддингов\n",
    "print(embeddings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bc94b-2143-4f2d-9ba9-8686d6a7d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Создаем DataFrame с эмбеддингами районов\n",
    "X_train_embeddings = pd.concat([pd.DataFrame(X_train), embeddings_df.loc[X_train['district']].reset_index(drop=True)], axis=1)\n",
    "X_test_embeddings = pd.concat([pd.DataFrame(X_test), embeddings_df.loc[X_test['district']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Удаляем лишний столбец district\n",
    "X_train_embeddings = X_train_embeddings.drop(columns=['district'])\n",
    "X_test_embeddings = X_test_embeddings.drop(columns=['district'])\n",
    "\n",
    "# Создаем и обучаем модель CatBoost\n",
    "catboost_model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='RMSE', verbose=100)\n",
    "\n",
    "catboost_model.fit(\n",
    "    X_train_embeddings,\n",
    "    y_train,\n",
    "    eval_set=(X_test_embeddings, y_test),\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "# Оцениваем модель на тестовых данных\n",
    "y_test_pred = catboost_model.predict(X_test_embeddings)\n",
    "catboost_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "catboost_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"CatBoost MAE: {catboost_mae:.2f}, CatBoost MAPE: {catboost_mape:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4580eb-749c-4e22-88c8-5a35d7aaa688",
   "metadata": {},
   "source": [
    "1. Зачем учитывать остальные факторы при кодировании района?\n",
    "Когда мы используем эмбеддинги для категориального признака \"район\" и одновременно учитываем остальные факторы (площадь, этаж, этажность, год постройки, отделка), мы помогаем модели лучше понять, как эти факторы взаимодействуют с районом. Это дает следующие преимущества:\n",
    "\n",
    "Учет взаимодействий : Эмбеддинги позволяют модели выявить и использовать взаимодействия между районом и другими признаками. Например, влияние района на цену может зависеть от этажности здания или состояния отделки.\n",
    "Улучшенная обобщающая способность : Модель может лучше обобщать, когда она учитывает все признаки сразу, так как она видит общую картину данных.\n",
    "\n",
    "2. Можно ли закодировать район без учета других факторов и цены?  \n",
    "Да, можно закодировать район с использованием эмбеддингов без учета других факторов и цены. Однако это может быть менее эффективным, так как модель не сможет учитывать взаимодействия между районом и другими признаками. Если вы хотите использовать эмбеддинги только для района, то модель будет обучаться на основе только этого признака, что может ограничить её способность делать точные предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3886b-dfd8-4b1c-9045-05d0e4e8a4de",
   "metadata": {},
   "source": [
    "1. Обучение нейросети : Мы обучаем нейросеть для получения эмбеддингов районов.\n",
    "2. Извлечение эмбеддингов : Мы извлекаем эмбеддинги районов и сохраняем их в DataFrame.\n",
    "3. Создание новых признаков : Мы создаем новые признаки, объединяя исходные признаки с эмбеддингами районов.\n",
    "4. Обучение бустинговой модели : Мы обучаем бустинговую модель (в данном случае CatBoost) на новых признаках, включая эмбеддинги районов.\n",
    "5. Оценка модели : Мы оцениваем модель на тестовых данных и выводим метрики MAE и MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952420bf-a830-4800-9ea9-93bb172ed409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
