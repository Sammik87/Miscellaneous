{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19557ad-7b2f-48d8-8536-02ea537f40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd011269-00da-42e2-ba4f-3c593987f3ca",
   "metadata": {},
   "source": [
    "# Расстояние Хаверсайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ebc5b-db3d-4b77-ba46-6742adb43795",
   "metadata": {},
   "source": [
    "# Находим сходство между объектами из разных таблиц по координатам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b91102-3148-4d67-9636-87b6aa3f6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления расстояния между двумя точками по координатам\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Преобразуем градусы в радианы\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    \n",
    "    # Создаем массив для координат\n",
    "    coords_1 = np.array([[lat1_rad, lon1_rad]])\n",
    "    coords_2 = np.array([[lat2_rad, lon2_rad]])\n",
    "    \n",
    "    # Вычисляем расстояние\n",
    "    return haversine_distances(coords_1, coords_2) * 6371000  # Умножаем на радиус Земли в метрах\n",
    "\n",
    "# Загрузка данных\n",
    "table1 = pd.read_csv('table1.csv')  # Замените на ваш путь к файлу\n",
    "table2 = pd.read_csv('table2.csv')  # Замените на ваш путь к файлу\n",
    "\n",
    "# Создаем новый столбец для хранения индексов схожих объектов\n",
    "table1['similar_indices'] = [[] for _ in range(len(table1))]\n",
    "\n",
    "# Определяем порог расстояния (в метрах)\n",
    "distance_threshold = 500\n",
    "\n",
    "# Вычисляем расстояния и заполняем столбец\n",
    "for i, row1 in table1.iterrows():\n",
    "    for j, row2 in table2.iterrows():\n",
    "        distance = calculate_distance(row1['lat'], row1['lon'], row2['lat'], row2['lon'])\n",
    "        if distance < distance_threshold:\n",
    "            table1.at[i, 'similar_indices'].append(j)\n",
    "\n",
    "# Сохранение результата в новый CSV файл\n",
    "table1.to_csv('table1_with_similar.csv', index = False)\n",
    "\n",
    "# Визуализация\n",
    "def plot_similar_objects(row1, table2):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    \n",
    "    # Плотность объектов из таблицы 2\n",
    "    plt.scatter(table2['lon'], table2['lat'], color = 'blue', label = 'Элитное жилье', alpha = 0.5)\n",
    "\n",
    "    # Объект из таблицы 1\n",
    "    plt.scatter(row1['lon'], row1['lat'], color = 'red', label = 'Объект из таблицы 1', s = 100)\n",
    "\n",
    "    # Схожие объекты\n",
    "    for index in row1['similar_indices']:\n",
    "        plt.scatter(table2.iloc[index]['lon'], table2.iloc[index]['lat'], color = 'green', label = 'Схожий объект', alpha = 0.7)\n",
    "\n",
    "    plt.title('Схожие объекты')\n",
    "    plt.xlabel('Долгота')\n",
    "    plt.ylabel('Широта')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Визуализируем для первого объекта из таблицы 1\n",
    "plot_similar_objects(table1.iloc[0], table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30470ba5-8767-4963-a6ae-2cbec75a7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Загрузка данных (замените 'table1.csv' и 'table2.csv' на ваши файлы)\n",
    "df1 = pd.read_csv('table1.csv', encoding='utf-8')\n",
    "df2 = pd.read_csv('table2.csv', encoding='utf-8')\n",
    "\n",
    "# Предполагаем, что столбцы с координатами называются 'latitude' и 'longitude'\n",
    "df1['coordinates'] = list(zip(df1['latitude'], df1['longitude']))\n",
    "df2['coordinates'] = list(zip(df2['latitude'], df2['longitude']))\n",
    "\n",
    "\n",
    "def find_matches(row, df2, max_distance_km):\n",
    "    \"\"\"Находит совпадения в df2 для данной строки из df1.\"\"\"\n",
    "    matches = []\n",
    "    for index, row2 in df2.iterrows():\n",
    "        distance = geodesic(row['coordinates'], row2['coordinates']).km\n",
    "        if distance <= max_distance_km:\n",
    "            matches.append(row2)\n",
    "    return matches\n",
    "\n",
    "# Задайте максимальное расстояние в километрах (настройте по необходимости)\n",
    "max_distance_km = 0.1  # Например, 100 метров\n",
    "\n",
    "# Применяем функцию к каждой строке df1\n",
    "df1['matches'] = df1.apply(lambda row: find_matches(row, df2, max_distance_km), axis=1)\n",
    "\n",
    "#  Вывод результатов.  Обратите внимание, что 'matches' - это список DataFrame\n",
    "print(df1)\n",
    "\n",
    "#Если нужно получить  более удобный для анализа формат, например,  создать столбец с ID совпавших квартир или другими данными:\n",
    "#Пример: добавим ID из df2 к результатам\n",
    "df1['matched_ids'] = df1['matches'].apply(lambda x: [row['id'] for row in x] if len(x)>0 else []) #id - предполагаемое имя столбца с ID в df2\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8557ed3-65d5-4d5a-8cac-eda96946da8f",
   "metadata": {},
   "source": [
    "1. geopy.distance.geodesic:  Эта функция вычисляет географическое расстояние между двумя точками, используя алгоритм Vincenty.  Это гораздо точнее, чем косинусное сходство для географических данных.\n",
    "\n",
    "2. max_distance_km:  Этот параметр задает радиус поиска.  Экспериментируйте с его значением, чтобы найти оптимальное значение для вашего набора данных.  Начните с небольшого значения (например, 0.1 км или 100 метров), если вы ищете квартиры в одном и том же доме.\n",
    "\n",
    "3. find_matches: Эта функция итерируется по df2 и находит все квартиры, расстояние до которых меньше max_distance_km.\n",
    "\n",
    "4. Обработка результатов:  Результирующий df1 будет содержать столбец matches, который содержит списки DataFrame с совпадениями из df2.  Вы можете дальше обработать эти списки для извлечения необходимых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8f7a6-dbce-4b5a-9639-88b3f2c04434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем матрицу косинусного сходства\n",
    "cosine_similarities = cosine_similarity(df1['features'], df2['features'])\n",
    "\n",
    "# еще обнулить диагональ!!!\n",
    "# Устанавливаем порог для отбора: чем выше порог, тем строже соответствие\n",
    "threshold = 0.999  # Настройте по необходимости\n",
    "\n",
    "# Получаем индексы совпадений для каждой строки df1\n",
    "matches = []\n",
    "for i in range(len(df1)):\n",
    "    matches.append([j for j in range(len(df2)) if cosine_similarities[i][j] >= threshold])\n",
    "\n",
    "# Добавляем список совпадений в df1\n",
    "df1['matches'] = matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe74a77-b440-43e1-874b-0bcceae0dcb7",
   "metadata": {},
   "source": [
    "# Нормализация матрицы сходства "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863cb167-2339-428d-ae75-315c7af0540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# ... (загрузка данных, вычисление cosine_similarities, как в предыдущих примерах) ...\n",
    "\n",
    "\n",
    "def normalize_similarity_matrix(similarity_matrix, method='row'):\n",
    "    \"\"\"Нормализует матрицу сходства.\"\"\"\n",
    "    if method == 'row':\n",
    "        row_sums = np.sum(similarity_matrix, axis=1, keepdims=True)\n",
    "        normalized_matrix = similarity_matrix / row_sums\n",
    "        normalized_matrix = np.nan_to_num(normalized_matrix) # Обработка NaN, которые могут возникнуть при нулевой сумме строки.\n",
    "        return normalized_matrix\n",
    "    elif method == 'column':\n",
    "        col_sums = np.sum(similarity_matrix, axis=0, keepdims=True)\n",
    "        normalized_matrix = similarity_matrix / col_sums\n",
    "        normalized_matrix = np.nan_to_num(normalized_matrix) # Обработка NaN\n",
    "        return normalized_matrix\n",
    "    elif method == 'global':\n",
    "        global_sum = np.sum(similarity_matrix)\n",
    "        normalized_matrix = similarity_matrix / global_sum\n",
    "        return normalized_matrix\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization method.\")\n",
    "\n",
    "\n",
    "# Нормализация по строке\n",
    "normalized_cosine_similarities_row = normalize_similarity_matrix(cosine_similarities, method = 'row')\n",
    "\n",
    "# Нормализация по столбцу\n",
    "normalized_cosine_similarities_col = normalize_similarity_matrix(cosine_similarities, method = 'column')\n",
    "\n",
    "# Глобальная нормализация\n",
    "normalized_cosine_similarities_global = normalize_similarity_matrix(cosine_similarities, method = 'global')\n",
    "\n",
    "\n",
    "# Вывод для сравнения:\n",
    "print(\"Оригинальная матрица:\")\n",
    "print(cosine_similarities)\n",
    "print(\"\\nНормализованная по строкам матрица:\")\n",
    "print(normalized_cosine_similarities_row)\n",
    "print(\"\\nНормализованная по столбцам матрица:\")\n",
    "print(normalized_cosine_similarities_col)\n",
    "print(\"\\nГлобально нормализованная матрица:\")\n",
    "print(normalized_cosine_similarities_global)\n",
    "\n",
    "# ... (Дальнейшая обработка с выбором порога, как описано в предыдущих ответах, но теперь\n",
    "#      используя  normalized_cosine_similarities_row,  normalized_cosine_similarities_col\n",
    "#      или normalized_cosine_similarities_global вместо cosine_similarities ) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782898d-72ac-46ed-b162-b081c7c71ce9",
   "metadata": {},
   "source": [
    "Выбор метода нормализации:\n",
    "\n",
    "• Нормализация по строке —  подходит, если вас интересует относительное сходство квартир из df1 с квартирами из df2.\n",
    "\n",
    "• Нормализация по столбцу — подходит, если вас интересует, насколько каждая квартира из df2 похожа на квартиры из df1.\n",
    "\n",
    "• Глобальная нормализация — подходит, если вы хотите получить относительное сходство между всеми парами квартир."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63983eb0-b8ea-49e1-9e2d-dba371f9daaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f15dadf-0e95-4058-8a78-79d8c7cba127",
   "metadata": {},
   "source": [
    "# Находим расстояние между объектами из разных таблиц (Квартира - Метро)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4f401-e87f-4fb0-a566-0741f1d27ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления расстояния по формуле Хаверсина\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Радиус Земли в километрах\n",
    "    lat1_rad = np.radians(lat1) #широта квартиры\n",
    "    lon1_rad = np.radians(lon1) #долгота квартиры\n",
    "    lat2_rad = np.radians(lat2) #широта метро\n",
    "    lon2_rad = np.radians(lon2) #долгота метро\n",
    "\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c  # Расстояние в километрах\n",
    "    return distance\n",
    "\n",
    "# Загрузка данных\n",
    "apartments = pd.read_csv('apartments.csv')  # Замените на ваш путь к файлу с квартирами\n",
    "metro_stations = pd.read_csv('metro_stations.csv')  # Замените на ваш путь к файлу со станциями метро\n",
    "\n",
    "# Создаем новые столбцы для ближайшей станции и расстояния\n",
    "apartments['nearest_metro'] = None\n",
    "apartments['distance_to_nearest_metro'] = None\n",
    "\n",
    "# Вычисляем расстояния\n",
    "for i, apartment in tqdm(apartments.iterrows(), total = apartments.shape[0], desc = 'Обработка квартир'):\n",
    "    min_distance = float('inf')\n",
    "    nearest_station = None\n",
    "    \n",
    "    for j, station in tqdm(metro_stations.iterrows(), total = metro_stations.shape[0], desc = 'Поиск ближайшей станции метро', leave = False):\n",
    "        distance = haversine(apartment['lat'], apartment['lon'], station['lat'], station['lon'])\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_station = station['name']  # Предполагается, что в таблице метро есть столбец 'name'\n",
    "    \n",
    "    apartments.at[i, 'nearest_metro'] = nearest_station\n",
    "    apartments.at[i, 'distance_to_nearest_metro'] = min_distance\n",
    "\n",
    "# Сохранение результата в новый CSV файл\n",
    "apartments.to_csv('apartments_with_nearest_metro.csv', index = False)\n",
    "\n",
    "print(\"Расчеты завершены. Результаты сохранены в 'apartments_with_nearest_metro.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be7927-5572-4738-a821-3637f5b7122d",
   "metadata": {},
   "source": [
    "# Евклидово расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2cb89-ef4f-4f0a-a12d-e01c5ba4f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных о квартирах (замените на ваши данные)\n",
    "apartments = pd.DataFrame({\n",
    "                           'apartment_id': range(1, 6),\n",
    "                           'lat': [55.75, 55.76, 55.77, 55.78, 55.79],\n",
    "                           'lon': [37.62, 37.63, 37.64, 37.65, 37.66]\n",
    "                         })\n",
    "\n",
    "# Пример данных о станциях метро (замените на ваши данные)\n",
    "stations = pd.DataFrame({\n",
    "                         'station_name': ['Station A', 'Station B', 'Station C'],\n",
    "                         'lat': [55.755, 55.775, 55.795],\n",
    "                         'lon': [37.625, 37.645, 37.665]\n",
    "                       })\n",
    "\n",
    "\n",
    "avg_lat_degree_meters = 111000\n",
    "\n",
    "def calculate_approx_distance(lat1, lon1, lat2, lon2):\n",
    "  \n",
    "    avg_lat_degree_meters = 111320\n",
    "    lat_diff_meters = abs(lat1 - lat2) * avg_lat_degree_meters\n",
    "\n",
    "    # Рассчитываем длину градуса долготы на основе средней широты\n",
    "    avg_latitude = (lat1 + lat2) / 2\n",
    "    avg_latitude_radians = math.radians(avg_latitude)\n",
    "    lon_degree_meters = 111320 * math.cos(avg_latitude_radians) # Более точный расчет\n",
    "    lon_diff_meters = abs(lon1 - lon2) * lon_degree_meters\n",
    "\n",
    "    return np.sqrt(lat_diff_meters**2 + lon_diff_meters**2)\n",
    "\n",
    "\n",
    "def find_closest_station(row, stations):\n",
    "    min_distance = float('inf')\n",
    "    closest_station = None\n",
    "    for index, station in stations.iterrows():\n",
    "        distance = calculate_euclidean_distance(row['lat'], row['lon'], station['lat'], station['lon'])\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_station = station['station_name']\n",
    "    return closest_station, min_distance\n",
    "\n",
    "\n",
    "apartments[['closest_station', 'distance']] = apartments.apply(lambda row: find_closest_station(row, stations), axis = 1).tolist()\n",
    "\n",
    "print(apartments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f59bde-cad7-4ff5-856f-af2d9b8b76a0",
   "metadata": {},
   "source": [
    "# Сходство объектов (сравнение векторов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049160cf-8618-4f20-80d7-213a06b8fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных (замените на ваши данные)\n",
    "data = pd.DataFrame({\n",
    "    'area': [50, 60, 70, 55, 65, 75, 52, 62, 72, 57],\n",
    "    'lon': [37.6, 37.7, 37.6, 37.7, 37.6, 37.7, 37.6, 37.7, 37.6, 37.7],\n",
    "    'lat': [55.7, 55.8, 55.7, 55.8, 55.7, 55.8, 55.7, 55.8, 55.7, 55.8],\n",
    "    'floor': [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],\n",
    "    'floors_total': [5, 5, 5, 10, 10, 10, 5, 5, 5, 10],\n",
    "    'year': [2000, 2005, 2010, 2000, 2005, 2010, 2000, 2005, 2010, 2000],\n",
    "    'district': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'distance_to_center': [5, 10, 15, 5, 10, 15, 5, 10, 15, 5],\n",
    "    'terrace': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1], # 0 - нет террасы, 1 - есть терраса\n",
    "    'price': [100000, 120000, 140000, 110000, 130000, 150000, 90000, 110000, 130000, 100000]\n",
    "})\n",
    "\n",
    "\n",
    "# Предобработка данных\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse_output = False)\n",
    "\n",
    "numerical_cols = ['area', 'lon', 'lat', 'floor', 'floors_total', 'year', 'distance_to_center']\n",
    "categorical_cols = ['district']\n",
    "\n",
    "data_numerical_scaled = scaler.fit_transform(data[numerical_cols])\n",
    "data_categorical_encoded = encoder.fit_transform(data[categorical_cols])\n",
    "\n",
    "data_processed = np.concatenate((data_numerical_scaled, data_categorical_encoded, data[['terrace']]), axis = 1)\n",
    "\n",
    "# Задаем веса признаков\n",
    "#weights = np.array([0.15, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2]) # пример весов\n",
    "\n",
    "# Задаем порог схожести\n",
    "similarity_threshold = 0.9 \n",
    "\n",
    "# Вычисление косинусной схожести с помощью векторизованных вычислений\n",
    "cosine_similarities = cosine_similarity(data_processed)\n",
    "# Обнуление главной диагонали матрицы схожести\n",
    "np.fill_diagonal(cosine_similarities, 0)\n",
    "\n",
    "# K-Means\n",
    "# kmeans = KMeans(n_clusters = 5)\n",
    "# kmeans.fit(similarity_matrix)\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# Вычисление взвешенного евклидова расстояния\n",
    "# distances = []\n",
    "# for i in range(len(data_processed)):\n",
    "#     row_distances = []\n",
    "#     for j in range(len(data_processed)):\n",
    "#         weighted_distance = np.sqrt(np.sum(weights * (data_processed[i] - data_processed[j])**2))\n",
    "#         row_distances.append(weighted_distance)\n",
    "#     distances.append(row_distances)\n",
    "# distances = np.array(distances)\n",
    "\n",
    "# Фильтрация по порогу\n",
    "similar_objects = []\n",
    "for i, row in enumerate(cosine_similarities): #distances\n",
    "    similar_indices = np.where(row <= similarity_threshold)[0].tolist()\n",
    "    similar_objects.append(similar_indices)\n",
    "\n",
    "data['similar_objects'] = similar_objects\n",
    "\n",
    "# Группировка по наличию террасы и анализ цен\n",
    "group_no_terrace = data[data['terrace'] == 0]\n",
    "group_terrace = data[data['terrace'] == 1]\n",
    "\n",
    "avg_price_no_terrace = group_no_terrace['price'].mean() / group_no_terrace['area'].mean()\n",
    "avg_price_terrace = group_terrace['price'].mean() / group_terrace['area'].mean()\n",
    "\n",
    "price_difference_percentage = ((avg_price_terrace - avg_price_no_terrace) / avg_price_no_terrace) * 100\n",
    "\n",
    "print(f\"Средняя удельная цена без террасы: {avg_price_no_terrace:.2f}\")\n",
    "print(f\"Средняя удельная цена с террасой: {avg_price_terrace:.2f}\")\n",
    "print(f\"Процентная разница в цене: {price_difference_percentage:.2f}%\")\n",
    "\n",
    "#Визуализация\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.scatter(data[data['terrace'] == 0]['area'], data[data['terrace'] == 0]['price'], label='Без террасы')\n",
    "plt.scatter(data[data['terrace'] == 1]['area'], data[data['terrace'] == 1]['price'], label='С террасой')\n",
    "plt.xlabel('Площадь')\n",
    "plt.ylabel('Цена')\n",
    "plt.legend()\n",
    "plt.title('Влияние наличия террасы на цену')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot([group_no_terrace['price'], group_terrace['price']], labels=['Без террасы', 'С террасой'])\n",
    "plt.ylabel('Цена')\n",
    "plt.title('Сравнение цен с помощью box plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e846c0-a202-49c1-93f1-f476fc253d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор первого объекта и его похожих объектов\n",
    "first_object_index = 0\n",
    "similar_indices = data['similar_objects'][first_object_index]\n",
    "\n",
    "# Создание новой таблицы с похожими объектами\n",
    "similar_objects_df = data.iloc[similar_indices].copy()\n",
    "\n",
    "# Вывод информации\n",
    "print(\"Первый объект:\")\n",
    "print(data.iloc[first_object_index])\n",
    "print(\"\\nПохожие объекты:\")\n",
    "print(similar_objects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7b978-d75f-4df3-89fd-e31ed5ca4240",
   "metadata": {},
   "source": [
    "# NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7bf03-a74b-46dd-86f9-5e47f021c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Пример данных (замените на ваши данные)\n",
    "data = {\n",
    "    'площадь': [50, 60, 70, 55, 65, 75, 52, 62],\n",
    "    'этаж': [3, 5, 2, 4, 1, 6, 2, 7],\n",
    "    'год_постройки': [2010, 2015, 2005, 2012, 2008, 2018, 2009, 2016],\n",
    "    'район': [1, 2, 1, 3, 2, 1, 3, 2],\n",
    "    'широта': [55.75, 55.76, 55.74, 55.755, 55.765, 55.745, 55.77, 55.758],\n",
    "    'долгота': [37.62, 37.63, 37.61, 37.625, 37.635, 37.615, 37.64, 37.628]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Нормализация данных (важно для большинства методов поиска ближайших соседей)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# k-NN с Ball Tree\n",
    "k = 3  # Количество ближайших соседей\n",
    "knn = NearestNeighbors(n_neighbors=k, algorithm='ball_tree')\n",
    "knn.fit(scaled_data)\n",
    "\n",
    "# Поиск похожих квартир (например, для первой квартиры)\n",
    "distances, indices = knn.kneighbors(scaled_data[0].reshape(1, -1))\n",
    "\n",
    "print(\"Показатели для первой квартиры:\", df.iloc[0])\n",
    "print(\"Индексы ближайших соседей:\", indices[0])\n",
    "print(\"Показатели ближайших соседей:\")\n",
    "print(df.iloc[indices[0]])\n",
    "print(\"Расстояния до ближайших соседей:\", distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170b988-d48e-454a-9b6d-599724440020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cityblock #Для Manhattan distance\n",
    "\n",
    "# Пример данных (замените на ваши данные)\n",
    "data = {\n",
    "    'площадь': [50, 60, 70, 55, 65, 75, 52, 62, 80, 45],\n",
    "    'этаж': [3, 5, 2, 4, 1, 6, 2, 7, 10, 1],\n",
    "    'год_постройки': [2010, 2015, 2005, 2012, 2008, 2018, 2009, 2016, 2020, 2000],\n",
    "    'район': [1, 2, 1, 3, 2, 1, 3, 2, 1, 4],\n",
    "    'широта': [55.75, 55.76, 55.74, 55.755, 55.765, 55.745, 55.77, 55.758, 55.752, 55.78],\n",
    "    'долгота': [37.62, 37.63, 37.61, 37.625, 37.635, 37.615, 37.64, 37.628, 37.618, 37.65]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# k-NN с KD-деревом и Manhattan distance\n",
    "k = 3  # Количество ближайших соседей\n",
    "knn = NearestNeighbors(n_neighbors=k, algorithm='kd_tree', metric='manhattan') # metric='manhattan' - ключевое изменение\n",
    "knn.fit(scaled_data)\n",
    "\n",
    "# Поиск похожих квартир (например, для первой квартиры)\n",
    "distances, indices = knn.kneighbors(scaled_data[0].reshape(1, -1))\n",
    "\n",
    "print(\"Показатели для первой квартиры:\", df.iloc[0])\n",
    "print(\"Индексы ближайших соседей:\", indices[0])\n",
    "print(\"Показатели ближайших соседей:\")\n",
    "print(df.iloc[indices[0]])\n",
    "print(\"Расстояния до ближайших соседей (Manhattan):\", distances[0])\n",
    "\n",
    "\n",
    "#Пример использования cityblock для сравнения одной пары:\n",
    "\n",
    "квартира1 = scaled_data[0]\n",
    "квартира2 = scaled_data[1]\n",
    "\n",
    "расстояние_manhattan = cityblock(квартира1, квартира2)\n",
    "print(f\"Расстояние Manhattan между квартирой 1 и 2: {расстояние_manhattan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca24a7-86f2-4774-b268-30df4813504c",
   "metadata": {},
   "source": [
    "cityblock:  Функция cityblock из библиотеки scipy.spatial.distance напрямую вычисляет расстояние Manhattan между двумя векторами.  Этот пример показывает, как её использовать, если вам нужно рассчитать расстояние между отдельными парами квартир.\n",
    "\n",
    "Обратите внимание, что kd_tree эффективен для низкоразмерных данных.  Для высокоразмерных данных лучше использовать ball_tree или другие структуры данных, предназначенные для больших размерностей.  Если у вас много признаков,  возможно, стоит рассмотреть методы понижения размерности (PCA, t-SNE)  перед поиском ближайших соседей.  Это может улучшить как производительность, так и качество результатов.  Кроме того,  выбор между manhattan и euclidean зависит от вашей задачи и  характера данных.  Эксперименты на ваших данных помогут определить, какой метод работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b148f0-51a8-485c-b0b7-3f86a16566e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Пример данных (замените на ваши данные)\n",
    "data1 = {'latitude': [55.75, 55.76, 55.77], 'longitude': [37.62, 37.63, 37.64]}\n",
    "data2 = {'latitude': [55.755, 55.765, 55.775, 55.8, 55.7], 'longitude': [37.625, 37.635, 37.645, 37.7, 37.5]}\n",
    "\n",
    "таблица_1 = pd.DataFrame(data1)\n",
    "таблица_2 = pd.DataFrame(data2)\n",
    "\n",
    "\n",
    "# 1. Объединение таблиц для стандартизации\n",
    "combined_data = pd.concat([таблица_1, таблица_2])\n",
    "\n",
    "# 2. Стандартизация данных с помощью MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(combined_data)\n",
    "\n",
    "# 3. Разделение стандартизированных данных обратно на таблицы\n",
    "таблица_1_scaled = scaled_data[:len(таблица_1),:]\n",
    "таблица_2_scaled = scaled_data[len(таблица_1):,:]\n",
    "\n",
    "# 4. Подготовка данных для NearestNeighbors\n",
    "X1 = таблица_1_scaled # Данные из таблицы_1\n",
    "X2 = таблица_2_scaled # Данные из таблицы_2\n",
    "\n",
    "# 5. Создание и обучение модели NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric='manhattan') # Можно попробовать kd_tree или brute для сравнения\n",
    "knn.fit(X2)\n",
    "\n",
    "# 6. Поиск ближайших соседей\n",
    "distances, indices = knn.kneighbors(X1)\n",
    "\n",
    "# 7. Добавление индексов ближайших соседей в таблицу_2\n",
    "таблица_2['nearest_neighbor_index'] = indices.flatten()\n",
    "\n",
    "# 8. Вывод результатов\n",
    "print(\"Таблица 1 (оригинальные данные):\\n\", таблица_1)\n",
    "print(\"\\nТаблица 2 (оригинальные данные) с индексами ближайших соседей:\\n\", таблица_2)\n",
    "print(\"\\nТаблица 1 (масштабированные данные):\\n\", pd.DataFrame(таблица_1_scaled, columns=['latitude', 'longitude']))\n",
    "print(\"\\nТаблица 2 (масштабированные данные):\\n\", pd.DataFrame(таблица_2_scaled, columns=['latitude', 'longitude']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d2d39-9d14-4790-8b82-7e5e795fc073",
   "metadata": {},
   "source": [
    "Можно сделать 3 шага:\n",
    "1. Находим ближайшего соседа NearestNeighbors.\n",
    "2. Рассчитываем расстояние между координатами ОО и ближайшего соседа.\n",
    "3. Сравниваем адреса ОО и ближайшего соседа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860c2c9-1f73-4fa2-832e-9ef284c07f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321f033-ce15-4a54-bba8-a2b95402ddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
